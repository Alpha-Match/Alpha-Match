# 작업 요약: 데이터 흐름 및 캐싱 전략 설계
- **날짜**: 2025-12-16

## 1. 개요
- 사용자로부터 제공된 테이블 명세서(`table_specification.md`)와 Flyway 스크립트(`V1__init_database_schema.sql`)를 기반으로 시스템의 전체적인 데이터 흐름과 API 서버의 캐싱 전략을 설계하고 문서화했습니다.

## 2. 주요 작업 내용

### 가. 데이터 흐름 설계 (`DATA_FLOW.md`)
- **End-to-End 흐름 정의**: Python 서버의 데이터 로딩부터 Batch 서버의 저장, API 서버의 조회, 프론트엔드의 렌더링까지 이어지는 전체 데이터 파이프라인을 정의했습니다.
- **시각화**: `Mermaid` 시퀀스 다이어그램을 사용하여 데이터 흐름을 시각적으로 표현하고, 각 단계별 상호작용(gRPC, GraphQL, DB 쿼리 등)을 명확히 했습니다.
- **3단계 분리**: 데이터 수집/저장(Ingestion), 캐시 관리(Management), 데이터 조회/렌더링(Serving)의 3단계로 나누어 각 프로세스를 상세히 설명했습니다.

### 나. 캐싱 전략 설계 (`CACHING_STRATEGY.md`)
- **다계층 캐싱 아키텍처 수립**: API 서버의 읽기 성능 최적화를 위해 **L1(Caffeine) + L2(Redis)**의 2단계 캐싱 구조를 설계했습니다.
- **계층별 역할 정의**:
    - **L1 (In-Memory)**: 가장 빠른 응답을 위해 단일 조회 결과 등 작은 데이터를 각 서버 인스턴스에 저장합니다.
    - **L2 (Distributed)**: 여러 인스턴스가 공유하며, 복잡한 쿼리 결과 등 상대적으로 큰 데이터를 중앙에서 관리합니다.
- **캐시 무효화 전략**:
    - **gRPC 기반 트리거**: Batch 서버가 데이터 업데이트를 완료하면 gRPC를 통해 API 서버에 캐시 무효화를 요청하는 방식으로 데이터 정합성을 보장합니다.
    - **전체 삭제(Flush)**: 구현의 복잡성을 낮추고 확실한 정합성을 보장하기 위해, 무효화 요청 시 모든 캐시 키를 삭제하는 단순하고 강력한 전략을 채택했습니다.
- **동시성 제어**: 캐시 무효화 작업 중 발생할 수 있는 Race Condition을 방지하기 위해 `AtomicBoolean` 또는 Lock을 사용해야 함을 명시했습니다.

### 다. 프론트엔드 상태 관리 및 캐싱 전략 확정 (2025-12-17)
- **배경**: 기존 설계는 백엔드 중심으로 작성되어, 프론트엔드의 구체적인 상태 관리 방안이 정의되지 않았습니다.
- **확정 내용**: 코드베이스 분석 및 `GEMINI.md` 문서 업데이트를 통해 프론트엔드의 기술 스택을 다음과 같이 확정했습니다.
  - **서버 상태 및 캐싱**: **Apollo Client (`InMemoryCache`)** 를 사용하여 GraphQL 데이터 페칭과 클라이언트 사이드 캐싱을 관리합니다. (기존 논의되었던 `React Query`는 사용하지 않음)
  - **전역 UI 상태**: **Redux Toolkit**을 사용하여 UI와 관련된 전역 상태(예: 모달, 테마 등)를 관리합니다.
- **의의**: 이를 통해 프론트엔드의 데이터 흐름과 상태 관리 책임이 명확해졌으며, 관련 공식 문서(`GEMINI.md`, `CACHING_STRATEGY.md`)도 모두 현행화되었습니다.

