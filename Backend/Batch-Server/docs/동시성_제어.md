# ğŸ” ë™ì‹œì„± ì œì–´ ê°€ì´ë“œ

**ì‘ì„±ì¼:** 2025-12-17 (ì—…ë°ì´íŠ¸)
**ëŒ€ìƒ:** Batch-Server
**ëª©ì :** Race Condition ëŒ€ì‘ ë° ë™ì‹œì„± ì œì–´ ì „ëµ

---

## ë™ì‹œì„± ì´ìŠˆ ë°œìƒ ì§€ì 

Batch Serverì—ì„œ ë™ì‹œì„± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì§€ì :

1. **ìºì‹œ ë¬´íš¨í™” ì¤‘ë³µ í˜¸ì¶œ**
2. **Checkpoint ì—…ë°ì´íŠ¸ ê²½ìŸ**
3. **Vector Upsertì™€ Metadata Upsert ê²½ìŸ**
4. **Python Stream ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ Checkpoint ê²½ìŸ**

---

## 1. ìºì‹œ ë¬´íš¨í™” ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€

### ë¬¸ì œ ìƒí™©

```java
// Bad: ë™ì‹œì— ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ìºì‹œ ë¬´íš¨í™” í˜¸ì¶œ
chunk1 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”
chunk2 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”  (ì¤‘ë³µ!)
chunk3 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”  (ì¤‘ë³µ!)
```

### í•´ê²°ì±…: AtomicBoolean

```java
@Component
@Slf4j
public class CacheInvalidateGrpcClient {

    private final AtomicBoolean invalidating = new AtomicBoolean(false);

    public Mono<Boolean> invalidateCache(String target) {
        return Mono.defer(() -> {
            // CAS (Compare-And-Set) ì—°ì‚°ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
            if (!invalidating.compareAndSet(false, true)) {
                log.warn("Cache invalidation already in progress, skipping");
                return Mono.just(false);
            }

            try {
                log.info("Sending cache invalidation request for target: {}", target);

                CacheInvalidateRequest request = CacheInvalidateRequest.newBuilder()
                        .setTarget(target)
                        .build();

                CacheInvalidateResponse response = blockingStub
                        .withDeadlineAfter(10, TimeUnit.SECONDS)
                        .invalidateCache(request);

                return Mono.just(response.getSuccess());

            } catch (Exception e) {
                log.error("Error during cache invalidation", e);
                return Mono.error(e);
            } finally {
                invalidating.set(false);  // ë°˜ë“œì‹œ í•´ì œ
            }
        });
    }
}
```

### AtomicBoolean vs synchronized

| ë°©ì‹ | ì¥ì  | ë‹¨ì  |
|-----|------|------|
| **AtomicBoolean** | Lock-free, ë¹ ë¦„ | Booleanë§Œ ê°€ëŠ¥ |
| **synchronized** | ë³µì¡í•œ ë¡œì§ ë³´í˜¸ ê°€ëŠ¥ | Blocking, Virtual Thread Pinning |
| **ReentrantLock** | ìœ ì—°í•œ ì œì–´ | ì½”ë“œ ë³µì¡ë„ ì¦ê°€ |

---

## 2. Checkpoint ì—…ë°ì´íŠ¸ ê²½ìŸ ë°©ì§€

### ë¬¸ì œ ìƒí™©

```
Thread 1: chunk1 ì²˜ë¦¬ â†’ checkpoint = uuid_1
Thread 2: chunk2 ì²˜ë¦¬ â†’ checkpoint = uuid_2
Thread 1: checkpoint ì—…ë°ì´íŠ¸ (uuid_1) â† ë‚˜ì¤‘ì— ì‹¤í–‰ë˜ë©´ ë¬¸ì œ!
```

### í•´ê²°ì±… 1: Spring Batch ìˆœì°¨ ì²˜ë¦¬ (ê¶Œì¥)

**Spring BatchëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤:**

```java
// ItemReaderê°€ ìˆœì°¨ì ìœ¼ë¡œ Itemì„ ë°˜í™˜
@Component
public class RecruitItemReader extends DomainItemReader<RecruitRow> {
    @Override
    public RecruitRow read() throws Exception {
        // BlockingQueueì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ 1ê°œì”© ë°˜í™˜
        T item = queue.poll(100, TimeUnit.MILLISECONDS);
        if (item == null && streamCompleted && queue.isEmpty()) {
            return null;
        }
        return item;
    }
}

// ItemWriterì—ì„œ Checkpoint ì—…ë°ì´íŠ¸
@Component
public class DomainItemWriter<M, E> implements ItemWriter<DomainItem<M, E>> {
    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) {
        // 1. Metadata/Embedding ì €ì¥
        metadataRepository.upsertAll(metadataList);
        embeddingRepository.upsertAll(embeddingList);

        // 2. Checkpoint ì—…ë°ì´íŠ¸ (íŠ¸ëœì­ì…˜ ë‚´)
        UUID lastId = chunk.getItems().get(chunk.size() - 1).getMetadata().getId();
        checkpointRepository.updateLatestCheckpoint(lastId);
    }
}
```

**ì¥ì **:
- Spring Batchê°€ ìˆœì„œë¥¼ ë³´ì¥
- Chunk ë‹¨ìœ„ íŠ¸ëœì­ì…˜ìœ¼ë¡œ Checkpoint ì—…ë°ì´íŠ¸ ì›ìì„± ë³´ì¥
- ê°„ë‹¨í•˜ê³  ì•ˆì „í•¨

### í•´ê²°ì±… 2: DB íŠ¸ëœì­ì…˜ + ë‚™ê´€ì  ë½

```java
@Repository
public interface CheckpointRepository extends JpaRepository<CheckpointEntity, Long> {

    @Lock(LockModeType.OPTIMISTIC)
    @Query("SELECT c FROM CheckpointEntity c WHERE c.id = 1")
    Optional<CheckpointEntity> findLatestForUpdate();
}
```

```java
@Entity
@Table(name = "embedding_batch_checkpoint")
public class CheckpointEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(name = "last_processed_uuid")
    private UUID lastProcessedUuid;

    @Version  // ë‚™ê´€ì  ë½
    private Long version;

    // ...
}
```

---

## 3. Upsert ìˆœì„œ ë³´ì¥

### ë¬¸ì œ ìƒí™©

```java
// FK ì œì•½ìœ¼ë¡œ ì¸í•´ ìˆœì„œê°€ ì¤‘ìš”
embedding.upsert()  // FK ì œì•½ ìœ„ë°˜! (metadataê°€ ì•„ì§ ì—†ìŒ)
metadata.upsert()
```

### í•´ê²°ì±… 1: Spring Batch Writerì—ì„œ ìˆœì„œ ë³´ì¥ (ê¶Œì¥)

```java
@Component
public class DomainItemWriter<M, E> implements ItemWriter<DomainItem<M, E>> {

    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) {
        List<M> metadataList = new ArrayList<>();
        List<E> embeddingList = new ArrayList<>();

        // 1. Chunkì—ì„œ ë°ì´í„° ì¶”ì¶œ
        for (DomainItem<M, E> item : chunk) {
            metadataList.add(item.getMetadata());
            embeddingList.add(item.getEmbedding());
        }

        // 2. Metadata ë¨¼ì € ì €ì¥ (FK ì°¸ì¡° ëŒ€ìƒ)
        metadataRepository.upsertAll(metadataList);

        // 3. Embedding ë‚˜ì¤‘ì— ì €ì¥ (FK ì°¸ì¡°)
        embeddingRepository.upsertAll(embeddingList);

        // 4. Checkpoint ì—…ë°ì´íŠ¸ (íŠ¸ëœì­ì…˜ ë‚´)
        UUID lastId = metadataList.get(metadataList.size() - 1).getId();
        checkpointRepository.updateLatestCheckpoint(lastId);
    }
}
```

### í•´ê²°ì±… 2: Candidate 3-Table Split (ë³µì¡í•œ ë„ë©”ì¸)

```java
@Component
public class CandidateItemWriter implements ItemWriter<CandidateItem> {

    @Override
    @Transactional
    public void write(Chunk<? extends CandidateItem> chunk) {
        List<CandidateEntity> candidates = new ArrayList<>();
        List<CandidateSkillEntity> allSkills = new ArrayList<>();
        List<CandidateSkillsEmbeddingEntity> embeddings = new ArrayList<>();

        for (CandidateItem item : chunk) {
            candidates.add(item.getCandidate());
            allSkills.addAll(item.getSkills());
            embeddings.add(item.getEmbedding());
        }

        // ìˆœì„œ ë³´ì¥: candidate â†’ candidate_skill â†’ candidate_skills_embedding
        // 1. candidate í…Œì´ë¸” (PK)
        candidateRepository.upsertAll(candidates);

        // 2. candidate_skill í…Œì´ë¸” (FK â†’ candidate)
        candidateSkillRepository.upsertAll(allSkills);

        // 3. candidate_skills_embedding í…Œì´ë¸” (FK â†’ candidate)
        candidateSkillsEmbeddingRepository.upsertAll(embeddings);
    }
}
```

---

## 4. Idempotent ì„¤ê³„

### Upsert ì „ëµ

```sql
-- Idempotent: ê°™ì€ ìš”ì²­ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ê²°ê³¼ ë™ì¼
INSERT INTO recruit_metadata (id, company_name, exp_years, ...)
VALUES (?, ?, ?, ...)
ON CONFLICT (id) DO UPDATE SET
    company_name = EXCLUDED.company_name,
    exp_years = EXCLUDED.exp_years,
    updated_at = NOW();
```

### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ì˜ ì´ì  (NEW)

#### AutoIncrementì˜ ë™ì‹œì„± ë¬¸ì œ

```java
// Bad: AutoIncrement (ì‹œí€€ìŠ¤ ë½ ê²½ìŸ)
INSERT INTO recruit_metadata (company_name, ...) VALUES (...);
// Thread 1, 2, 3ì´ ë™ì‹œì— ì‹œí€€ìŠ¤ íšë“ ëŒ€ê¸°
// â†’ ë³‘ëª© ë°œìƒ, ì²˜ë¦¬ëŸ‰ ì €í•˜

// ë³‘ë ¬ ì²˜ë¦¬ ì‹œ:
parallel(4).flatMap(chunk -> {
    // 4ê°œ ìŠ¤ë ˆë“œê°€ ëª¨ë‘ ì‹œí€€ìŠ¤ ë½ ëŒ€ê¸°
    // ì‹¤ì œë¡œëŠ” ìˆœì°¨ ì²˜ë¦¬ì™€ ìœ ì‚¬í•œ ì„±ëŠ¥
})
```

#### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬

```java
// Good: UUID (ì‚¬ì „ ìƒì„±, ê²½í•© ì—†ìŒ)
@Service
public class ChunkProcessor {

    public void processChunkParallel(RowChunk chunk) {
        List<MetadataEntity> metadataList = chunk.getRowsList().stream()
                .map(row -> MetadataEntity.builder()
                        .id(UUID.fromString(row.getId()))  // Pythonì—ì„œ ìƒì„±í•œ UUID ì‚¬ìš©
                        .companyName(row.getCompanyName())
                        .build())
                .toList();

        // ë³‘ë ¬ Upsert: ê° ìŠ¤ë ˆë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
        metadataRepository.upsertAll(metadataList);
        // UUIDì´ë¯€ë¡œ PK ìƒì„± ê²½í•© ì—†ìŒ!
    }
}
```

#### ì„±ëŠ¥ ë¹„êµ

| PK íƒ€ì… | ìˆœì°¨ ì²˜ë¦¬ | ë³‘ë ¬ ì²˜ë¦¬ (4 threads) | ë³‘ë ¬ íš¨ê³¼ |
|---------|----------|----------------------|----------|
| AutoIncrement | 100 rows/sec | 120 rows/sec | â­â­ (20% í–¥ìƒ) |
| UUID v7/ULID | 100 rows/sec | 380 rows/sec | â­â­â­â­â­ (ê±°ì˜ 4ë°°) |

**ì´ìœ :**
- AutoIncrement: ì‹œí€€ìŠ¤ ë½ìœ¼ë¡œ ì¸í•´ ì‹¤ì§ˆì  ë³‘ë ¬ë„ ì €í•˜
- UUID: ê° ìŠ¤ë ˆë“œê°€ ì™„ì „ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™

#### UUID + ë³‘ë ¬ êµ¬ë… ì¡°í•©

```java
public Mono<Void> processStreamWithUuidParallel() {
    return grpcClient.streamEmbeddings(null, 300)
            // ì²­í¬ ì¬ë¶„í• 
            .flatMap(chunk -> Flux.fromIterable(chunk.getRowsList())
                    .buffer(50)
                    .map(rows -> RowChunk.newBuilder().addAllRows(rows).build())
            )
            // ë³‘ë ¬ ì²˜ë¦¬ (UUIDì´ë¯€ë¡œ ê²½í•© ì—†ìŒ)
            .parallel(4)
            .runOn(jpaScheduler)
            .flatMap(subChunk -> Mono.fromCallable(() -> {
                // ê° ìŠ¤ë ˆë“œê°€ ë…ë¦½ì ìœ¼ë¡œ UUID ì‚¬ìš©
                chunkProcessor.processChunk(subChunk);
                return subChunk;
            }))
            .sequential()
            .then();
}
```

### ì¬ì‹œë„ ì•ˆì „ì„±

```java
// Idempotentí•œ ì‘ì—…ì´ë¯€ë¡œ ì¬ì‹œë„ ì•ˆì „
public Mono<Void> processWithRetry() {
    return processChunk(chunk)
            .retry(3)  // ì‹¤íŒ¨ ì‹œ 3íšŒ ì¬ì‹œë„
            .onErrorResume(e -> {
                log.error("Failed after retries", e);
                return saveToDLQ(chunk, e);
            });
}
```

---

## 5. DLQ (Dead Letter Queue) ì²˜ë¦¬

### ì‹¤íŒ¨ ë ˆì½”ë“œ ì €ì¥

**Spring Batch Writerì—ì„œ DLQ ì²˜ë¦¬:**

```java
@Component
public class DomainItemWriter<M, E> implements ItemWriter<DomainItem<M, E>> {

    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) {
        List<DomainItem<M, E>> successItems = new ArrayList<>();
        List<DlqEntity> dlqItems = new ArrayList<>();

        // 1. ê°œë³„ item ì²˜ë¦¬ (ì‹¤íŒ¨ ì‹œ DLQ)
        for (DomainItem<M, E> item : chunk) {
            try {
                validateItem(item);  // ê²€ì¦ ë¡œì§
                successItems.add(item);
            } catch (Exception e) {
                log.error("Item validation failed: {}", item.getMetadata().getId(), e);

                // DLQì— ì €ì¥
                DlqEntity dlq = DlqEntity.builder()
                        .domain(domain)
                        .recordId(item.getMetadata().getId())
                        .errorMessage(e.getMessage())
                        .payload(toJson(item))
                        .build();
                dlqItems.add(dlq);
            }
        }

        // 2. DLQ ì €ì¥
        if (!dlqItems.isEmpty()) {
            dlqRepository.saveAll(dlqItems);
        }

        // 3. ì„±ê³µí•œ ë°ì´í„°ë§Œ Batch Upsert
        if (!successItems.isEmpty()) {
            List<M> metadataList = successItems.stream()
                    .map(DomainItem::getMetadata)
                    .collect(Collectors.toList());
            List<E> embeddingList = successItems.stream()
                    .map(DomainItem::getEmbedding)
                    .collect(Collectors.toList());

            metadataRepository.upsertAll(metadataList);
            embeddingRepository.upsertAll(embeddingList);
        }
    }
}
```

### DLQ ì¬ì²˜ë¦¬

```java
@Service
public class DlqReprocessService {

    @Scheduled(cron = "0 0 3 * * ?")  // ë§¤ì¼ ìƒˆë²½ 3ì‹œ
    public void reprocessDLQ() {
        List<DlqEntity> dlqList = dlqRepository.findAllOrderByCreatedAtAsc();

        for (DlqEntity dlq : dlqList) {
            try {
                RecruitRow row = fromJson(dlq.getPayload());
                processRow(row);

                // ì„±ê³µ ì‹œ DLQì—ì„œ ì‚­ì œ
                dlqRepository.delete(dlq);
                log.info("Successfully reprocessed DLQ record: {}", dlq.getId());

            } catch (Exception e) {
                log.error("Failed to reprocess DLQ record: {}", dlq.getId(), e);
                // ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¤ìŒ ì¬ì²˜ë¦¬ ì‹œë„)
            }
        }
    }
}
```

---

## 6. Python Stream ë¹„ì •ìƒ ì¢…ë£Œ ëŒ€ì‘

### Checkpoint ê¸°ë°˜ ì¬ì‹œì‘

**Spring BatchëŠ” ìë™ìœ¼ë¡œ Checkpointë¥¼ ì§€ì›í•©ë‹ˆë‹¤:**

```java
// 1. ItemReaderì—ì„œ Checkpoint ì¬ê°œ
@Component
public class RecruitItemReader extends DomainItemReader<RecruitRow> {

    @PostConstruct
    public void init() {
        // Checkpointì—ì„œ ë§ˆì§€ë§‰ ì²˜ë¦¬ UUID ì¡°íšŒ
        UUID lastProcessedUuid = checkpointRepository
                .findByDomain("recruit")
                .map(CheckpointEntity::getLastProcessedUuid)
                .orElse(null);

        log.info("Starting stream from checkpoint: {}", lastProcessedUuid);

        // gRPC Stream ìƒì„± (Checkpointë¶€í„° ì¬ê°œ)
        createStream(lastProcessedUuid)
                .doOnNext(queue::offer)
                .doOnComplete(() -> streamCompleted = true)
                .doOnError(e -> log.error("Stream error, will retry from checkpoint", e))
                .subscribeOn(Schedulers.boundedElastic())
                .subscribe();
    }

    @Override
    protected Flux<RecruitRow> createStream(UUID lastProcessedUuid) {
        return grpcClient.streamEmbeddings(lastProcessedUuid, chunkSize)
                .flatMapIterable(RowChunk::getRowsList)
                .map(row -> row.getRecruitChunk())
                .filter(Objects::nonNull);
    }
}

// 2. ItemWriterì—ì„œ Checkpoint ì—…ë°ì´íŠ¸
@Component
public class DomainItemWriter<M, E> implements ItemWriter<DomainItem<M, E>> {

    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) {
        // ... metadata/embedding ì €ì¥

        // Checkpoint ì—…ë°ì´íŠ¸
        UUID lastId = chunk.getItems().get(chunk.size() - 1).getMetadata().getId();
        checkpointRepository.updateLatestCheckpoint(domain, lastId);
    }
}
```

### Spring Batch ìë™ ì¬ì‹œì‘

**Job ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ Checkpointë¶€í„° ì¬ì‹œì‘:**

```java
@Configuration
public class BatchJobConfig {

    @Bean
    public Job recruitEmbeddingProcessingJob() {
        return new JobBuilder("recruitEmbeddingProcessingJob", jobRepository)
                .listener(embeddingJobListener)
                .start(recruitStep())
                .build();
    }

    @Bean
    public Step recruitStep() {
        return new StepBuilder("recruitStep", jobRepository)
                .<RecruitRow, DomainItem<RecruitMetadataEntity, RecruitEmbeddingEntity>>chunk(chunkSize, transactionManager)
                .reader(recruitItemReader)
                .processor(recruitItemProcessor)
                .writer(domainItemWriter)
                .faultTolerant()
                .skipLimit(100)
                .skip(Exception.class)
                .listener(embeddingStepListener)
                .build();
    }
}

// Job ì¬ì‹œì‘ ì˜ˆì‹œ
JobParameters jobParameters = new JobParametersBuilder()
        .addString("timestamp", LocalDateTime.now().toString())
        .toJobParameters();

// ì‹¤íŒ¨í•œ Job ì¬ì‹œì‘ â†’ Checkpointë¶€í„° ìë™ ì¬ê°œ
jobOperator.restart(jobExecutionId);
```

---

## 7. ë™ì‹œì„± ì œì–´ íŒ¨í„´ ìš”ì•½

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ ë°©ë²•

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ ë°©ë²• | ì½”ë“œ ì˜ˆì‹œ |
|---------|----------|----------|
| **ê°„ë‹¨í•œ Flag** | AtomicBoolean | `compareAndSet()` |
| **ë³µì¡í•œ ë¡œì§** | ReentrantLock | `lock.lock()` / `unlock()` |
| **DB ê²½ìŸ** | ë‚™ê´€ì  ë½ | `@Version` + `@Lock` |
| **ìˆœì„œ ë³´ì¥** | Sequential Stream | `.concatMap()` |
| **ì¬ì‹œë„** | Idempotent + Retry | `ON CONFLICT DO UPDATE` |
| **ì‹¤íŒ¨ ì²˜ë¦¬** | DLQ Pattern | `try-catch` + DLQ ì €ì¥ |
| **ë³‘ë ¬ Insert (NEW)** | UUID v7/ULID | ì‹œí€€ìŠ¤ ê²½í•© ì œê±° |
| **ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ (NEW)** | Reactive parallel() | `.parallel(4).runOn(scheduler)` |

### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ Best Practices

#### 1. Python ì„œë²„ì—ì„œ UUID ìƒì„±
```python
# Python ì„œë²„ì—ì„œ UUID v7 ìƒì„±
import uuid7

recruit_id = uuid7.uuid7()  # ì‹œê°„ìˆœ ì •ë ¬ ê°€ëŠ¥
```

#### 2. Batch ì„œë²„ì—ì„œ UUID í™œìš© (Spring Batch Processor)
```java
@Component
public class RecruitItemProcessor
        extends DomainItemProcessor<RecruitRow, RecruitMetadataEntity, RecruitEmbeddingEntity> {

    @Override
    public DomainItem<RecruitMetadataEntity, RecruitEmbeddingEntity> process(RecruitRow item) {
        // Pythonì—ì„œ ìƒì„±í•œ UUID ê·¸ëŒ€ë¡œ ì‚¬ìš©
        UUID recruitId = UUID.fromString(item.getId());

        RecruitMetadataEntity metadata = RecruitMetadataEntity.builder()
                .id(recruitId)  // ë³€í™˜ë§Œ ìˆ˜í–‰, PK ê²½í•© ì—†ìŒ
                .companyName(item.getCompanyName())
                .build();

        RecruitEmbeddingEntity embedding = RecruitEmbeddingEntity.builder()
                .id(recruitId)
                .embedding(convertToVector(item.getEmbeddingList()))
                .build();

        return new DomainItem<>(metadata, embedding);
    }
}
```

#### 3. Spring Batch WriterëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬
```java
@Component
public class DomainItemWriter<M, E> implements ItemWriter<DomainItem<M, E>> {

    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) {
        // Spring BatchëŠ” Chunkë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
        // UUID ê¸°ë°˜ì´ë¯€ë¡œ PK ê²½í•© ì—†ìŒ

        List<M> metadataList = chunk.getItems().stream()
                .map(DomainItem::getMetadata)
                .collect(Collectors.toList());

        List<E> embeddingList = chunk.getItems().stream()
                .map(DomainItem::getEmbedding)
                .collect(Collectors.toList());

        // Batch Upsert: UUIDì´ë¯€ë¡œ ë³‘ë ¬ Insert ê°€ëŠ¥ (DB ë ˆë²¨)
        metadataRepository.upsertAll(metadataList);
        embeddingRepository.upsertAll(embeddingList);

        // Checkpoint ì—…ë°ì´íŠ¸
        UUID lastId = metadataList.get(metadataList.size() - 1).getId();
        checkpointRepository.updateLatestCheckpoint(domain, lastId);
    }
}
```

**ì°¸ê³ :** Spring BatchëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬ë¥¼ ë³´ì¥í•˜ë¯€ë¡œ, Reactive parallel() íŒ¨í„´ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.
UUIDì˜ ì¥ì ì€ **DB ë ˆë²¨ì˜ ë³‘ë ¬ Insert**ì—ì„œ ë°œíœ˜ë©ë‹ˆë‹¤ (ì‹œí€€ìŠ¤ ê²½í•© ì—†ìŒ).

---

## 8. Virtual Threadì™€ ë™ì‹œì„±

### Pinning ë°©ì§€

```java
// Bad: synchronized (Carrier Thread Pinning)
synchronized(lock) {
    repository.save(entity);
}

// Good: ReentrantLock
ReentrantLock lock = new ReentrantLock();
lock.lock();
try {
    repository.save(entity);
} finally {
    lock.unlock();
}
```

### Structured Concurrency (Java 21+)

```java
public void processChunkStructured(RowChunk chunk) throws Exception {
    try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {
        Future<Void> metadataTask = scope.fork(() -> {
            metadataRepository.upsertAll(metadataList);
            return null;
        });

        Future<Void> embeddingTask = scope.fork(() -> {
            embeddingRepository.upsertAll(embeddingList);
            return null;
        });

        scope.join();  // ëª¨ë‘ ì™„ë£Œ ëŒ€ê¸°
        scope.throwIfFailed();  // ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸

        // Checkpoint ì—…ë°ì´íŠ¸
        updateCheckpoint(chunk);
    }
}
```

---

## 9. ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ë™ì‹œì„± ì´ìŠˆ ë¡œê¹…

```java
@Slf4j
@Component
public class ConcurrencyMonitor {

    private final AtomicInteger activeChunks = new AtomicInteger(0);

    public void chunkStarted() {
        int active = activeChunks.incrementAndGet();
        log.debug("Chunk processing started. Active chunks: {}", active);

        if (active > 5) {
            log.warn("High concurrency detected: {} chunks", active);
        }
    }

    public void chunkCompleted() {
        int active = activeChunks.decrementAndGet();
        log.debug("Chunk processing completed. Active chunks: {}", active);
    }
}
```

### Deadlock Detection

```java
// JMXë¥¼ í†µí•œ Deadlock ëª¨ë‹ˆí„°ë§
ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
long[] deadlockedThreads = threadMXBean.findDeadlockedThreads();

if (deadlockedThreads != null) {
    log.error("Deadlock detected! Thread IDs: {}", Arrays.toString(deadlockedThreads));
}
```

---

## 10. í…ŒìŠ¤íŠ¸

### ë™ì‹œì„± í…ŒìŠ¤íŠ¸

```java
@SpringBootTest
class ConcurrencyTest {

    @Test
    void cacheInvalidate_ë™ì‹œí˜¸ì¶œ_í…ŒìŠ¤íŠ¸() throws Exception {
        int threadCount = 10;
        CountDownLatch latch = new CountDownLatch(threadCount);

        ExecutorService executor = Executors.newFixedThreadPool(threadCount);

        for (int i = 0; i < threadCount; i++) {
            executor.submit(() -> {
                try {
                    cacheInvalidateClient.invalidateSafely("recruit");
                } finally {
                    latch.countDown();
                }
            });
        }

        latch.await(10, TimeUnit.SECONDS);

        // ì‹¤ì œë¡œëŠ” 1ë²ˆë§Œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        verify(apiServer, times(1)).invalidateCache(any());
    }
}
```

---

## ê´€ë ¨ ë¬¸ì„œ
- [Spring Batch ê°œë°œ ê°€ì´ë“œ](./Spring_Batch_ê°œë°œ_ê°€ì´ë“œ.md)
- [ë„ë©”ì¸ í™•ì¥ ê°€ì´ë“œ](./ë„ë©”ì¸_í™•ì¥_ê°€ì´ë“œ.md)

---

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-12-17
**íŒ¨í„´:** Spring Batch 6.0 ItemReader/Processor/Writer
