# ğŸ” ë™ì‹œì„± ì œì–´ ë° Race Condition ëŒ€ì‘

**ì‘ì„±ì¼:** 2025-12-10
**ì—…ë°ì´íŠ¸:** 2025-12-10

---

## ë™ì‹œì„± ì´ìŠˆ ë°œìƒ ì§€ì 

Batch Serverì—ì„œ ë™ì‹œì„± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì§€ì :

1. **ìºì‹œ ë¬´íš¨í™” ì¤‘ë³µ í˜¸ì¶œ**
2. **Checkpoint ì—…ë°ì´íŠ¸ ê²½ìŸ**
3. **Vector Upsertì™€ Metadata Upsert ê²½ìŸ**
4. **Python Stream ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ Checkpoint ê²½ìŸ**

---

## 1. ìºì‹œ ë¬´íš¨í™” ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€

### ë¬¸ì œ ìƒí™©

```java
// Bad: ë™ì‹œì— ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ìºì‹œ ë¬´íš¨í™” í˜¸ì¶œ
chunk1 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”
chunk2 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”  (ì¤‘ë³µ!)
chunk3 ì²˜ë¦¬ ì™„ë£Œ â†’ API Server ìºì‹œ ë¬´íš¨í™”  (ì¤‘ë³µ!)
```

### í•´ê²°ì±…: AtomicBoolean

```java
@Component
@Slf4j
public class CacheInvalidateGrpcClient {

    private final AtomicBoolean invalidating = new AtomicBoolean(false);

    public Mono<Boolean> invalidateCache(String target) {
        return Mono.defer(() -> {
            // CAS (Compare-And-Set) ì—°ì‚°ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
            if (!invalidating.compareAndSet(false, true)) {
                log.warn("Cache invalidation already in progress, skipping");
                return Mono.just(false);
            }

            try {
                log.info("Sending cache invalidation request for target: {}", target);

                CacheInvalidateRequest request = CacheInvalidateRequest.newBuilder()
                        .setTarget(target)
                        .build();

                CacheInvalidateResponse response = blockingStub
                        .withDeadlineAfter(10, TimeUnit.SECONDS)
                        .invalidateCache(request);

                return Mono.just(response.getSuccess());

            } catch (Exception e) {
                log.error("Error during cache invalidation", e);
                return Mono.error(e);
            } finally {
                invalidating.set(false);  // ë°˜ë“œì‹œ í•´ì œ
            }
        });
    }
}
```

### AtomicBoolean vs synchronized

| ë°©ì‹ | ì¥ì  | ë‹¨ì  |
|-----|------|------|
| **AtomicBoolean** | Lock-free, ë¹ ë¦„ | Booleanë§Œ ê°€ëŠ¥ |
| **synchronized** | ë³µì¡í•œ ë¡œì§ ë³´í˜¸ ê°€ëŠ¥ | Blocking, Virtual Thread Pinning |
| **ReentrantLock** | ìœ ì—°í•œ ì œì–´ | ì½”ë“œ ë³µì¡ë„ ì¦ê°€ |

---

## 2. Checkpoint ì—…ë°ì´íŠ¸ ê²½ìŸ ë°©ì§€

### ë¬¸ì œ ìƒí™©

```
Thread 1: chunk1 ì²˜ë¦¬ â†’ checkpoint = uuid_1
Thread 2: chunk2 ì²˜ë¦¬ â†’ checkpoint = uuid_2
Thread 1: checkpoint ì—…ë°ì´íŠ¸ (uuid_1) â† ë‚˜ì¤‘ì— ì‹¤í–‰ë˜ë©´ ë¬¸ì œ!
```

### í•´ê²°ì±… 1: ìˆœì°¨ ì²˜ë¦¬ (ê¶Œì¥)

```java
@Service
public class StreamingService {

    public Mono<Void> processStream() {
        return grpcClient.streamEmbeddings(null, 300)
                .concatMap(chunk -> processChunkSequential(chunk))  // ìˆœì°¨ ì²˜ë¦¬
                .then();
    }

    private Mono<Void> processChunkSequential(RowChunk chunk) {
        return Mono.fromCallable(() -> {
            chunkProcessor.processChunk(chunk);
            return chunk;
        })
        .publishOn(jpaScheduler)
        .then();
    }
}
```

### í•´ê²°ì±… 2: DB íŠ¸ëœì­ì…˜ + ë‚™ê´€ì  ë½

```java
@Repository
public interface CheckpointRepository extends JpaRepository<CheckpointEntity, Long> {

    @Lock(LockModeType.OPTIMISTIC)
    @Query("SELECT c FROM CheckpointEntity c WHERE c.id = 1")
    Optional<CheckpointEntity> findLatestForUpdate();
}
```

```java
@Entity
@Table(name = "embedding_batch_checkpoint")
public class CheckpointEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(name = "last_processed_uuid")
    private UUID lastProcessedUuid;

    @Version  // ë‚™ê´€ì  ë½
    private Long version;

    // ...
}
```

---

## 3. Upsert ìˆœì„œ ë³´ì¥

### ë¬¸ì œ ìƒí™©

```java
// FK ì œì•½ìœ¼ë¡œ ì¸í•´ ìˆœì„œê°€ ì¤‘ìš”
embedding.upsert()  // FK ì œì•½ ìœ„ë°˜! (metadataê°€ ì•„ì§ ì—†ìŒ)
metadata.upsert()
```

### í•´ê²°ì±…: ëª…ì‹œì  ìˆœì„œ ì§€ì •

```java
@Service
public class ChunkProcessor {

    @Transactional
    public void processChunk(RowChunk chunk) {
        List<MetadataEntity> metadataList = /* ... */;
        List<EmbeddingEntity> embeddingList = /* ... */;

        // 1. Metadata ë¨¼ì € ì €ì¥ (FK ì°¸ì¡° ëŒ€ìƒ)
        metadataRepository.upsertAll(metadataList);

        // 2. Embedding ë‚˜ì¤‘ì— ì €ì¥ (FK ì°¸ì¡°)
        embeddingRepository.upsertAll(embeddingList);

        // 3. Checkpoint ì—…ë°ì´íŠ¸
        UUID lastId = getLastId(chunk);
        checkpointRepository.updateLatestCheckpoint(lastId);
    }
}
```

---

## 4. Idempotent ì„¤ê³„

### Upsert ì „ëµ

```sql
-- Idempotent: ê°™ì€ ìš”ì²­ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ê²°ê³¼ ë™ì¼
INSERT INTO recruit_metadata (id, company_name, exp_years, ...)
VALUES (?, ?, ?, ...)
ON CONFLICT (id) DO UPDATE SET
    company_name = EXCLUDED.company_name,
    exp_years = EXCLUDED.exp_years,
    updated_at = NOW();
```

### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ì˜ ì´ì  (NEW)

#### AutoIncrementì˜ ë™ì‹œì„± ë¬¸ì œ

```java
// Bad: AutoIncrement (ì‹œí€€ìŠ¤ ë½ ê²½ìŸ)
INSERT INTO recruit_metadata (company_name, ...) VALUES (...);
// Thread 1, 2, 3ì´ ë™ì‹œì— ì‹œí€€ìŠ¤ íšë“ ëŒ€ê¸°
// â†’ ë³‘ëª© ë°œìƒ, ì²˜ë¦¬ëŸ‰ ì €í•˜

// ë³‘ë ¬ ì²˜ë¦¬ ì‹œ:
parallel(4).flatMap(chunk -> {
    // 4ê°œ ìŠ¤ë ˆë“œê°€ ëª¨ë‘ ì‹œí€€ìŠ¤ ë½ ëŒ€ê¸°
    // ì‹¤ì œë¡œëŠ” ìˆœì°¨ ì²˜ë¦¬ì™€ ìœ ì‚¬í•œ ì„±ëŠ¥
})
```

#### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬

```java
// Good: UUID (ì‚¬ì „ ìƒì„±, ê²½í•© ì—†ìŒ)
@Service
public class ChunkProcessor {

    public void processChunkParallel(RowChunk chunk) {
        List<MetadataEntity> metadataList = chunk.getRowsList().stream()
                .map(row -> MetadataEntity.builder()
                        .id(UUID.fromString(row.getId()))  // Pythonì—ì„œ ìƒì„±í•œ UUID ì‚¬ìš©
                        .companyName(row.getCompanyName())
                        .build())
                .toList();

        // ë³‘ë ¬ Upsert: ê° ìŠ¤ë ˆë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
        metadataRepository.upsertAll(metadataList);
        // UUIDì´ë¯€ë¡œ PK ìƒì„± ê²½í•© ì—†ìŒ!
    }
}
```

#### ì„±ëŠ¥ ë¹„êµ

| PK íƒ€ì… | ìˆœì°¨ ì²˜ë¦¬ | ë³‘ë ¬ ì²˜ë¦¬ (4 threads) | ë³‘ë ¬ íš¨ê³¼ |
|---------|----------|----------------------|----------|
| AutoIncrement | 100 rows/sec | 120 rows/sec | â­â­ (20% í–¥ìƒ) |
| UUID v7/ULID | 100 rows/sec | 380 rows/sec | â­â­â­â­â­ (ê±°ì˜ 4ë°°) |

**ì´ìœ :**
- AutoIncrement: ì‹œí€€ìŠ¤ ë½ìœ¼ë¡œ ì¸í•´ ì‹¤ì§ˆì  ë³‘ë ¬ë„ ì €í•˜
- UUID: ê° ìŠ¤ë ˆë“œê°€ ì™„ì „ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™

#### UUID + ë³‘ë ¬ êµ¬ë… ì¡°í•©

```java
public Mono<Void> processStreamWithUuidParallel() {
    return grpcClient.streamEmbeddings(null, 300)
            // ì²­í¬ ì¬ë¶„í• 
            .flatMap(chunk -> Flux.fromIterable(chunk.getRowsList())
                    .buffer(50)
                    .map(rows -> RowChunk.newBuilder().addAllRows(rows).build())
            )
            // ë³‘ë ¬ ì²˜ë¦¬ (UUIDì´ë¯€ë¡œ ê²½í•© ì—†ìŒ)
            .parallel(4)
            .runOn(jpaScheduler)
            .flatMap(subChunk -> Mono.fromCallable(() -> {
                // ê° ìŠ¤ë ˆë“œê°€ ë…ë¦½ì ìœ¼ë¡œ UUID ì‚¬ìš©
                chunkProcessor.processChunk(subChunk);
                return subChunk;
            }))
            .sequential()
            .then();
}
```

### ì¬ì‹œë„ ì•ˆì „ì„±

```java
// Idempotentí•œ ì‘ì—…ì´ë¯€ë¡œ ì¬ì‹œë„ ì•ˆì „
public Mono<Void> processWithRetry() {
    return processChunk(chunk)
            .retry(3)  // ì‹¤íŒ¨ ì‹œ 3íšŒ ì¬ì‹œë„
            .onErrorResume(e -> {
                log.error("Failed after retries", e);
                return saveToDLQ(chunk, e);
            });
}
```

---

## 5. DLQ (Dead Letter Queue) ì²˜ë¦¬

### ì‹¤íŒ¨ ë ˆì½”ë“œ ì €ì¥

```java
@Service
public class ChunkProcessor {

    public void processChunkWithDLQ(RowChunk chunk) {
        for (RecruitRow row : chunk.getRowsList()) {
            try {
                processRow(row);
            } catch (Exception e) {
                log.error("Failed to process row: {}", row.getId(), e);

                // DLQì— ì €ì¥
                DlqEntity dlq = DlqEntity.builder()
                        .recruitId(UUID.fromString(row.getId()))
                        .errorMessage(e.getMessage())
                        .payload(toJson(row))
                        .build();

                dlqRepository.save(dlq);
            }
        }
    }
}
```

### DLQ ì¬ì²˜ë¦¬

```java
@Service
public class DlqReprocessService {

    @Scheduled(cron = "0 0 3 * * ?")  // ë§¤ì¼ ìƒˆë²½ 3ì‹œ
    public void reprocessDLQ() {
        List<DlqEntity> dlqList = dlqRepository.findAllOrderByCreatedAtAsc();

        for (DlqEntity dlq : dlqList) {
            try {
                RecruitRow row = fromJson(dlq.getPayload());
                processRow(row);

                // ì„±ê³µ ì‹œ DLQì—ì„œ ì‚­ì œ
                dlqRepository.delete(dlq);
                log.info("Successfully reprocessed DLQ record: {}", dlq.getId());

            } catch (Exception e) {
                log.error("Failed to reprocess DLQ record: {}", dlq.getId(), e);
                // ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¤ìŒ ì¬ì²˜ë¦¬ ì‹œë„)
            }
        }
    }
}
```

---

## 6. Python Stream ë¹„ì •ìƒ ì¢…ë£Œ ëŒ€ì‘

### Checkpoint ê¸°ë°˜ ì¬ì‹œì‘

```java
@Service
public class StreamingService {

    public Mono<Void> processStreamWithRecovery() {
        return checkpointRepository.findLastProcessedUuid()
                .map(lastUuid -> {
                    log.info("Resuming from checkpoint: {}", lastUuid);
                    return lastUuid;
                })
                .defaultIfEmpty((UUID) null)
                .flatMap(lastUuid ->
                    grpcClient.streamEmbeddings(lastUuid, 300)
                            .concatMap(this::processChunk)
                            .onErrorResume(e -> {
                                log.error("Stream error, will retry from checkpoint", e);
                                return Mono.empty();
                            })
                )
                .then();
    }
}
```

### Stream ì¬ì—°ê²° ë¡œì§

```java
public Mono<Void> processStreamWithAutoRetry() {
    return Mono.defer(() -> processStreamWithRecovery())
            .retryWhen(Retry.backoff(3, Duration.ofSeconds(5))
                    .filter(throwable -> throwable instanceof StatusRuntimeException)
                    .doBeforeRetry(retrySignal ->
                            log.warn("Retrying stream (attempt: {})",
                                    retrySignal.totalRetries() + 1)
                    )
            );
}
```

---

## 7. ë™ì‹œì„± ì œì–´ íŒ¨í„´ ìš”ì•½

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ ë°©ë²•

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ ë°©ë²• | ì½”ë“œ ì˜ˆì‹œ |
|---------|----------|----------|
| **ê°„ë‹¨í•œ Flag** | AtomicBoolean | `compareAndSet()` |
| **ë³µì¡í•œ ë¡œì§** | ReentrantLock | `lock.lock()` / `unlock()` |
| **DB ê²½ìŸ** | ë‚™ê´€ì  ë½ | `@Version` + `@Lock` |
| **ìˆœì„œ ë³´ì¥** | Sequential Stream | `.concatMap()` |
| **ì¬ì‹œë„** | Idempotent + Retry | `ON CONFLICT DO UPDATE` |
| **ì‹¤íŒ¨ ì²˜ë¦¬** | DLQ Pattern | `try-catch` + DLQ ì €ì¥ |
| **ë³‘ë ¬ Insert (NEW)** | UUID v7/ULID | ì‹œí€€ìŠ¤ ê²½í•© ì œê±° |
| **ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ (NEW)** | Reactive parallel() | `.parallel(4).runOn(scheduler)` |

### UUID ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ Best Practices

#### 1. Python ì„œë²„ì—ì„œ UUID ìƒì„±
```python
# Python ì„œë²„ì—ì„œ UUID v7 ìƒì„±
import uuid7

recruit_id = uuid7.uuid7()  # ì‹œê°„ìˆœ ì •ë ¬ ê°€ëŠ¥
```

#### 2. Batch ì„œë²„ì—ì„œ UUID í™œìš©
```java
@Service
public class ChunkProcessor {

    public void processChunk(RowChunk chunk) {
        // Pythonì—ì„œ ìƒì„±í•œ UUID ê·¸ëŒ€ë¡œ ì‚¬ìš©
        List<MetadataEntity> metadataList = chunk.getRowsList().stream()
                .map(row -> MetadataEntity.builder()
                        .id(UUID.fromString(row.getId()))  // ë³€í™˜ë§Œ ìˆ˜í–‰
                        .build())
                .toList();

        // ë³‘ë ¬ Upsert: PK ê²½í•© ì—†ìŒ
        metadataRepository.upsertAll(metadataList);
    }
}
```

#### 3. ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ë™ì‹œì„± ì œì–´
```java
public Mono<Void> processStreamOptimized() {
    return grpcClient.streamEmbeddings(null, 300)
            // ì²­í¬ ì¬ë¶„í• 
            .flatMap(chunk -> Flux.fromIterable(chunk.getRowsList())
                    .buffer(50)
                    .map(rows -> RowChunk.newBuilder().addAllRows(rows).build())
            )
            // ë³‘ë ¬ ì²˜ë¦¬
            .parallel(4)  // UUIDì´ë¯€ë¡œ ì•ˆì „
            .runOn(jpaScheduler)
            .flatMap(subChunk -> Mono.fromCallable(() -> {
                chunkProcessor.processChunk(subChunk);
                return subChunk;
            }))
            // ìˆœì°¨ ë³µê·€ (Checkpoint ìˆœì„œ ë³´ì¥)
            .sequential()
            .reduce((first, second) -> second)  // ë§ˆì§€ë§‰ ì²­í¬
            .doOnNext(lastChunk -> {
                UUID lastId = UUID.fromString(
                    lastChunk.getRows(lastChunk.getRowsCount() - 1).getId()
                );
                checkpointRepository.updateLatestCheckpoint(lastId);
            })
            .then();
}
```

---

## 8. Virtual Threadì™€ ë™ì‹œì„±

### Pinning ë°©ì§€

```java
// Bad: synchronized (Carrier Thread Pinning)
synchronized(lock) {
    repository.save(entity);
}

// Good: ReentrantLock
ReentrantLock lock = new ReentrantLock();
lock.lock();
try {
    repository.save(entity);
} finally {
    lock.unlock();
}
```

### Structured Concurrency (Java 21+)

```java
public void processChunkStructured(RowChunk chunk) throws Exception {
    try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {
        Future<Void> metadataTask = scope.fork(() -> {
            metadataRepository.upsertAll(metadataList);
            return null;
        });

        Future<Void> embeddingTask = scope.fork(() -> {
            embeddingRepository.upsertAll(embeddingList);
            return null;
        });

        scope.join();  // ëª¨ë‘ ì™„ë£Œ ëŒ€ê¸°
        scope.throwIfFailed();  // ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸

        // Checkpoint ì—…ë°ì´íŠ¸
        updateCheckpoint(chunk);
    }
}
```

---

## 9. ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ë™ì‹œì„± ì´ìŠˆ ë¡œê¹…

```java
@Slf4j
@Component
public class ConcurrencyMonitor {

    private final AtomicInteger activeChunks = new AtomicInteger(0);

    public void chunkStarted() {
        int active = activeChunks.incrementAndGet();
        log.debug("Chunk processing started. Active chunks: {}", active);

        if (active > 5) {
            log.warn("High concurrency detected: {} chunks", active);
        }
    }

    public void chunkCompleted() {
        int active = activeChunks.decrementAndGet();
        log.debug("Chunk processing completed. Active chunks: {}", active);
    }
}
```

### Deadlock Detection

```java
// JMXë¥¼ í†µí•œ Deadlock ëª¨ë‹ˆí„°ë§
ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
long[] deadlockedThreads = threadMXBean.findDeadlockedThreads();

if (deadlockedThreads != null) {
    log.error("Deadlock detected! Thread IDs: {}", Arrays.toString(deadlockedThreads));
}
```

---

## 10. í…ŒìŠ¤íŠ¸

### ë™ì‹œì„± í…ŒìŠ¤íŠ¸

```java
@SpringBootTest
class ConcurrencyTest {

    @Test
    void cacheInvalidate_ë™ì‹œí˜¸ì¶œ_í…ŒìŠ¤íŠ¸() throws Exception {
        int threadCount = 10;
        CountDownLatch latch = new CountDownLatch(threadCount);

        ExecutorService executor = Executors.newFixedThreadPool(threadCount);

        for (int i = 0; i < threadCount; i++) {
            executor.submit(() -> {
                try {
                    cacheInvalidateClient.invalidateSafely("recruit");
                } finally {
                    latch.countDown();
                }
            });
        }

        latch.await(10, TimeUnit.SECONDS);

        // ì‹¤ì œë¡œëŠ” 1ë²ˆë§Œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        verify(apiServer, times(1)).invalidateCache(any());
    }
}
```

---

## ê´€ë ¨ ë¬¸ì„œ
- [Reactive_Blocking_í˜¼í•©ì „ëµ](./Reactive_Blocking_í˜¼í•©ì „ëµ.md)
- [gRPC_í†µì‹ _ê°€ì´ë“œ](./gRPC_í†µì‹ _ê°€ì´ë“œ.md)
- [Batch ì„¤ê³„ì„œ](./Batchì„¤ê³„ì„œ.md)
