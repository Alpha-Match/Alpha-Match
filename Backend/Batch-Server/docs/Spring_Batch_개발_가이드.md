# Spring Batch ê°œë°œ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-12-17
**ëŒ€ìƒ**: Batch-Server
**ëª©ì **: Spring Batch 6.0 ê¸°ë°˜ ê°œë°œ íŒ¨í„´ ë° ì‹¤ì œ êµ¬í˜„ ê°€ì´ë“œ

---

## ğŸ“‹ ê°œìš”

Batch-ServerëŠ” **Spring Batch 6.0 + Java 21 + Virtual Thread**ë¥¼ ì‚¬ìš©í•˜ì—¬ Python AI Serverë¡œë¶€í„° Embedding ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³  PostgreSQL(pgvector)ì— ì €ì¥í•©ë‹ˆë‹¤.

### í•µì‹¬ ì•„í‚¤í…ì²˜

```
Python AI Server (gRPC Stream)
    â†“
Spring Batch Job
    â”œâ”€ ItemReader: gRPC Stream â†’ Queue â†’ Item
    â”œâ”€ ItemProcessor: Proto â†’ Entity ë³€í™˜
    â””â”€ ItemWriter: Batch Upsert (Metadata â†’ Embedding)
    â†“
PostgreSQL(pgvector) + DLQ + Checkpoint
```

---

## ğŸ—ï¸ Spring Batch 6.0 í•µì‹¬ íŒ¨í„´

### 1. ItemReader/Processor/Writer íŒ¨í„´

#### ItemReader
**ì—­í• **: ë°ì´í„° ì†ŒìŠ¤ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì½ì–´ Item ë‹¨ìœ„ë¡œ ë°˜í™˜

```java
@Component
public class RecruitItemReader extends DomainItemReader<RecruitRow> {

    private final EmbeddingGrpcClient grpcClient;
    private final CheckpointRepository checkpointRepository;

    @Override
    protected Flux<RecruitRow> createStream(UUID lastProcessedUuid) {
        int chunkSize = batchProperties.getChunkSize();

        return grpcClient.streamEmbeddings(lastProcessedUuid, chunkSize)
            .flatMapIterable(RowChunk::getRowsList)
            .map(row -> row.getRecruitChunk())
            .filter(Objects::nonNull);
    }
}
```

**DomainItemReader ì¶”ìƒ í´ë˜ìŠ¤**:
```java
public abstract class DomainItemReader<T> implements ItemReader<T> {

    private final BlockingQueue<T> queue = new LinkedBlockingQueue<>(1000);
    private volatile boolean streamCompleted = false;

    @PostConstruct
    public void init() {
        UUID lastProcessedUuid = getLastCheckpoint();

        createStream(lastProcessedUuid)
            .doOnNext(queue::offer)
            .doOnComplete(() -> streamCompleted = true)
            .subscribeOn(Schedulers.boundedElastic())
            .subscribe();
    }

    @Override
    public T read() throws Exception {
        T item = queue.poll(100, TimeUnit.MILLISECONDS);

        if (item == null && streamCompleted && queue.isEmpty()) {
            return null; // Stream ì¢…ë£Œ
        }

        return item;
    }

    protected abstract Flux<T> createStream(UUID lastProcessedUuid);
}
```

#### ItemProcessor
**ì—­í• **: Itemì„ ë³€í™˜í•˜ì—¬ Entityë¡œ ë°˜í™˜

```java
@Component
public class RecruitItemProcessor extends DomainItemProcessor<RecruitRow, RecruitMetadataEntity, RecruitEmbeddingEntity> {

    @Override
    public DomainItem<RecruitMetadataEntity, RecruitEmbeddingEntity> process(RecruitRow item) {
        UUID id = UUID.fromString(item.getId());

        // Metadata Entity
        RecruitMetadataEntity metadata = new RecruitMetadataEntity();
        metadata.setId(id);
        metadata.setCompanyName(item.getCompanyName());
        metadata.setExpYears(item.getExpYears());
        metadata.setEnglishLevel(item.getEnglishLevel());
        metadata.setPrimaryKeyword(item.getPrimaryKeyword());

        // Embedding Entity
        float[] vectorArray = convertToFloatArray(item.getVectorList());
        validateVectorDimension(vectorArray, id);

        RecruitEmbeddingEntity embedding = RecruitEmbeddingEntity.fromFloatArray(id, vectorArray);

        return new DomainItem<>(metadata, embedding);
    }

    private void validateVectorDimension(float[] vector, UUID id) {
        int expectedDim = batchProperties.getDomainConfig("recruit").getVectorDimension();
        if (vector.length != expectedDim) {
            throw new IllegalArgumentException(
                String.format("Vector dimension mismatch for UUID %s: expected=%d, actual=%d",
                    id, expectedDim, vector.length)
            );
        }
    }
}
```

**DomainItemProcessor ì¶”ìƒ í´ë˜ìŠ¤**:
```java
public abstract class DomainItemProcessor<I, M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemProcessor<I, DomainItem<M, E>> {

    @Autowired
    protected BatchProperties batchProperties;

    protected float[] convertToFloatArray(List<Float> vectorList) {
        float[] array = new float[vectorList.size()];
        for (int i = 0; i < vectorList.size(); i++) {
            array[i] = vectorList.get(i);
        }
        return array;
    }
}
```

#### ItemWriter
**ì—­í• **: Entityë¥¼ DBì— Batch Upsert

```java
@Component
public class DomainItemWriter<M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemWriter<DomainItem<M, E>> {

    private final JpaRepository<M, UUID> metadataRepository;
    private final JpaRepository<E, UUID> embeddingRepository;
    private final DlqService dlqService;

    @Override
    @Transactional
    public void write(Chunk<? extends DomainItem<M, E>> chunk) throws Exception {
        List<DomainItem<M, E>> items = chunk.getItems();

        List<M> successMetadata = new ArrayList<>();
        List<E> successEmbedding = new ArrayList<>();

        // 1. ê°œë³„ item ì²˜ë¦¬ (ì‹¤íŒ¨ ì‹œ DLQ)
        for (DomainItem<M, E> item : items) {
            try {
                successMetadata.add(item.getMetadata());
                successEmbedding.add(item.getEmbedding());
            } catch (Exception e) {
                log.error("Failed to process item: {}", item.getMetadata().getId(), e);
                dlqService.saveToDlq(getDomain(), item.getMetadata().getId(), e.getMessage(), toJson(item));
            }
        }

        // 2. Batch Upsert (ìˆœì„œ ì¤‘ìš”: metadata â†’ embedding)
        if (!successMetadata.isEmpty()) {
            metadataUpsertFunction.upsertAll(successMetadata);
            embeddingUpsertFunction.upsertAll(successEmbedding);
        }
    }
}
```

**DomainItem DTO**:
```java
@Getter
@AllArgsConstructor
public class DomainItem<M extends BaseMetadataEntity, E extends BaseEmbeddingEntity> {
    private final M metadata;
    private final E embedding;
}
```

---

### 2. DomainJobFactory (Factory Method íŒ¨í„´)

**ëª©ì **: ë„ë©”ì¸ë³„ Job/Stepì„ ë™ì ìœ¼ë¡œ ìƒì„±

```java
@Component
@RequiredArgsConstructor
public class DomainJobFactory {

    private final JobRepository jobRepository;
    private final PlatformTransactionManager transactionManager;
    private final BatchProperties batchProperties;

    // Reader/Processor/Writer Beans
    private final RecruitItemReader recruitItemReader;
    private final RecruitItemProcessor recruitItemProcessor;
    private final ApplicationContext applicationContext;

    /**
     * ë„ë©”ì¸ë³„ Job ìƒì„±
     */
    public Job createJob(String domain) {
        return switch (domain.toLowerCase()) {
            case "recruit" -> createRecruitJob();
            case "candidate" -> createCandidateJob();
            default -> throw new IllegalArgumentException("Unsupported domain: " + domain);
        };
    }

    private Job createRecruitJob() {
        return new JobBuilder("recruitEmbeddingProcessingJob", jobRepository)
                .listener(embeddingJobListener)
                .start(createRecruitStep())
                .build();
    }

    private Step createRecruitStep() {
        int chunkSize = batchProperties.getChunkSize();

        // Generic Writer ìƒì„±
        DomainItemWriter<RecruitMetadataEntity, RecruitEmbeddingEntity> writer =
            new DomainItemWriter<>(
                "recruit",
                recruitMetadataRepository,
                recruitEmbeddingRepository,
                metadataRepository::upsertAll,
                embeddingRepository::upsertAll,
                dlqService
            );

        return new StepBuilder("recruitEmbeddingStep", jobRepository)
                .<RecruitRow, DomainItem<RecruitMetadataEntity, RecruitEmbeddingEntity>>chunk(chunkSize, transactionManager)
                .reader(recruitItemReader)
                .processor(recruitItemProcessor)
                .writer(writer)
                .faultTolerant()
                .skip(Exception.class)
                .skipLimit(100)
                .listener(embeddingStepListener)
                .build();
    }
}
```

**BatchJobConfigì—ì„œ ì‚¬ìš©**:
```java
@Configuration
public class BatchJobConfig {

    private final DomainJobFactory domainJobFactory;

    @Bean
    public Job recruitEmbeddingProcessingJob() {
        return domainJobFactory.createJob("recruit");
    }

    @Bean
    public Job candidateEmbeddingProcessingJob() {
        return domainJobFactory.createJob("candidate");
    }
}
```

---

### 3. Quartz Scheduler í†µí•©

#### QuartzConfig
```java
@Configuration
public class QuartzConfig {

    @Bean
    public SchedulerFactoryBean schedulerFactoryBean(DataSource dataSource) {
        SchedulerFactoryBean factory = new SchedulerFactoryBean();
        factory.setDataSource(dataSource);
        factory.setQuartzProperties(quartzProperties());
        factory.setJobFactory(springBeanJobFactory());
        factory.setWaitForJobsToCompleteOnShutdown(true);
        factory.setAutoStartup(true);
        return factory;
    }

    private Properties quartzProperties() {
        Properties properties = new Properties();

        // JDBC JobStore
        properties.setProperty("org.quartz.jobStore.class", "org.quartz.impl.jdbcjobstore.JobStoreTX");
        properties.setProperty("org.quartz.jobStore.driverDelegateClass", "org.quartz.impl.jdbcjobstore.PostgreSQLDelegate");
        properties.setProperty("org.quartz.jobStore.tablePrefix", "QRTZ_");

        // ThreadPool
        properties.setProperty("org.quartz.threadPool.class", "org.quartz.simpl.SimpleThreadPool");
        properties.setProperty("org.quartz.threadPool.threadCount", "10");

        // Misfire
        properties.setProperty("org.quartz.jobStore.misfireThreshold", "60000");

        return properties;
    }
}
```

#### BatchSchedulerConfig
```java
@Configuration
@ConditionalOnProperty(name = "batch.scheduler.enabled", havingValue = "true")
public class BatchSchedulerConfig {

    @Value("${batch.scheduler.jobs.recruit.cron:0 0 2 * * ?}")
    private String recruitCronExpression;

    @Bean
    public JobDetail recruitEmbeddingJobDetail() {
        return JobBuilder.newJob(RecruitEmbeddingQuartzJob.class)
                .withIdentity("recruitEmbeddingJobDetail", "embedding")
                .storeDurably()
                .requestRecovery()
                .build();
    }

    @Bean
    public Trigger recruitEmbeddingTrigger(JobDetail recruitEmbeddingJobDetail) {
        return TriggerBuilder.newTrigger()
                .forJob(recruitEmbeddingJobDetail)
                .withSchedule(CronScheduleBuilder.cronSchedule(recruitCronExpression)
                        .inTimeZone(TimeZone.getTimeZone("Asia/Seoul"))
                        .withMisfireHandlingInstructionDoNothing())
                .build();
    }

    /**
     * Spring Batch 6.0 íŒ¨í„´: JobRegistry + JobOperator
     */
    public static class RecruitEmbeddingQuartzJob extends QuartzJobBean {

        private final JobRegistry jobRegistry;
        private final JobOperator jobOperator;

        @Override
        protected void executeInternal(JobExecutionContext context) throws JobExecutionException {
            try {
                // 1. JobRegistryì—ì„œ Job ê°ì²´ ê°€ì ¸ì˜¤ê¸°
                Job job = jobRegistry.getJob("recruitEmbeddingProcessingJob");

                // 2. JobParameters ìƒì„±
                JobParameters jobParameters = new JobParametersBuilder()
                        .addString("timestamp", new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss").format(new Date()))
                        .toJobParameters();

                // 3. Spring Batch Job ì‹¤í–‰
                JobExecution execution = jobOperator.start(job, jobParameters);

                log.info("Job Started | ExecutionId={}, Status={}", execution.getId(), execution.getStatus());

            } catch (JobExecutionAlreadyRunningException | JobRestartException |
                     JobInstanceAlreadyCompleteException | InvalidJobParametersException e) {
                throw new JobExecutionException("Job execution failed", e);
            }
        }
    }
}
```

**application.yml ì„¤ì •**:
```yaml
batch:
  scheduler:
    enabled: true
    jobs:
      recruit:
        cron: "0 0 2 * * ?"  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        enabled: true
      candidate:
        cron: "0 30 2 * * ?"  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ 30ë¶„
        enabled: false
```

---

## ğŸ”§ Virtual Thread ì‚¬ìš©

### ExecutorConfig
```java
@Configuration
public class ExecutorConfig {

    /**
     * Virtual Thread Executor (Java 21)
     * JPA ë“± Blocking I/O ì‘ì—…ìš©
     */
    @Bean(name = "virtualThreadExecutor")
    public Executor virtualThreadExecutor() {
        return Executors.newVirtualThreadPerTaskExecutor();
    }
}
```

### ì‚¬ìš© ì˜ˆì‹œ (ItemReader ë‚´ë¶€)
```java
public abstract class DomainItemReader<T> implements ItemReader<T> {

    @Autowired
    @Qualifier("virtualThreadExecutor")
    private Executor virtualThreadExecutor;

    @PostConstruct
    public void init() {
        createStream(lastProcessedUuid)
            .doOnNext(queue::offer)
            .subscribeOn(Schedulers.fromExecutor(virtualThreadExecutor))
            .subscribe();
    }
}
```

### Virtual Thread ì£¼ì˜ì‚¬í•­

#### âš ï¸ synchronized ì‚¬ìš© ê¸ˆì§€ (Pinning ë°œìƒ)
```java
// Bad: synchronized block (Carrier Thread Pinning)
synchronized(lock) {
    repository.save(entity);
}

// Good: ReentrantLock ì‚¬ìš©
ReentrantLock lock = new ReentrantLock();
lock.lock();
try {
    repository.save(entity);
} finally {
    lock.unlock();
}
```

#### âš ï¸ Connection Pool ê³ ê°ˆ ë°©ì§€
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20  # Virtual Thread ìˆ˜ì— ë§ê²Œ ì¡°ì •
```

---

## ğŸ“¡ gRPC í†µì‹ 

### Proto íŒŒì¼ ì •ì˜

**embedding_stream.proto**:
```protobuf
syntax = "proto3";

package embedding;

option java_multiple_files = true;
option java_package = "com.alpha.backend.grpc.proto";

service EmbeddingStreamService {
  rpc StreamEmbedding(StreamEmbeddingRequest) returns (stream RowChunk);
}

message StreamEmbeddingRequest {
  string last_processed_uuid = 1;  // Checkpoint UUID
  int32 chunk_size = 2;             // Chunk í¬ê¸°
}

message RowChunk {
  oneof chunk_data {
    RecruitRowChunk recruit_chunk = 1;
    CandidateRowChunk candidate_chunk = 2;
    SkillEmbeddingDicRowChunk skill_embedding_dic_chunk = 3;
  }
}

message RecruitRowChunk {
  repeated RecruitRow rows = 1;
}

message RecruitRow {
  string id = 1;                    // UUID
  string company_name = 2;
  int32 exp_years = 3;
  string english_level = 4;
  string primary_keyword = 5;
  repeated float vector = 6;        // 384d
}

message CandidateRowChunk {
  repeated CandidateRow rows = 1;
}

message CandidateRow {
  string candidate_id = 1;          // UUID
  string position_category = 2;
  int32 experience_years = 3;
  string original_resume = 4;
  repeated string skills = 5;       // Array
  repeated float skills_vector = 6; // 768d
}

message SkillEmbeddingDicRowChunk {
  repeated SkillEmbeddingDicRow rows = 1;
}

message SkillEmbeddingDicRow {
  string skill = 1;                 // String PK
  repeated float vector = 2;        // 768d
}
```

### EmbeddingGrpcClient
```java
@Component
@Slf4j
public class EmbeddingGrpcClient {

    private final ManagedChannel channel;
    private final EmbeddingStreamServiceGrpc.EmbeddingStreamServiceStub asyncStub;

    public Flux<RowChunk> streamEmbeddings(UUID lastProcessedUuid, int chunkSize) {
        Sinks.Many<RowChunk> sink = Sinks.many().unicast().onBackpressureBuffer();

        StreamEmbeddingRequest.Builder requestBuilder = StreamEmbeddingRequest.newBuilder()
                .setChunkSize(chunkSize);

        if (lastProcessedUuid != null) {
            requestBuilder.setLastProcessedUuid(lastProcessedUuid.toString());
        }

        asyncStub.streamEmbedding(requestBuilder.build(), new StreamObserver<>() {
            @Override
            public void onNext(RowChunk chunk) {
                sink.tryEmitNext(chunk);
            }

            @Override
            public void onError(Throwable throwable) {
                log.error("Error in embedding stream: {}", throwable.getMessage());
                sink.tryEmitError(throwable);
            }

            @Override
            public void onCompleted() {
                log.info("Embedding stream completed");
                sink.tryEmitComplete();
            }
        });

        return sink.asFlux();
    }
}
```

### CacheInvalidateGrpcClient
```java
@Component
@Slf4j
public class CacheInvalidateGrpcClient {

    private final ManagedChannel channel;
    private final CacheServiceGrpc.CacheServiceBlockingStub blockingStub;
    private final AtomicBoolean invalidating = new AtomicBoolean(false);

    /**
     * ìºì‹œ ë¬´íš¨í™” ìš”ì²­ (ë™ì‹œì„± ì œì–´)
     */
    public Mono<Boolean> invalidateCache(String target) {
        return Mono.defer(() -> {
            // CASë¡œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
            if (!invalidating.compareAndSet(false, true)) {
                log.warn("Cache invalidation already in progress, skipping");
                return Mono.just(false);
            }

            try {
                CacheInvalidateRequest request = CacheInvalidateRequest.newBuilder()
                        .setTarget(target)
                        .build();

                CacheInvalidateResponse response = blockingStub
                        .withDeadlineAfter(10, TimeUnit.SECONDS)
                        .invalidateCache(request);

                return Mono.just(response.getSuccess());

            } catch (StatusRuntimeException e) {
                log.error("gRPC error during cache invalidation: {}", e.getStatus());
                return Mono.error(e);
            } finally {
                invalidating.set(false);
            }
        })
        .retryWhen(Retry.backoff(3, Duration.ofSeconds(1)));
    }
}
```

---

## ğŸ¯ ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### Recruit ë„ë©”ì¸ ì „ì²´ í”Œë¡œìš°

#### 1. Entity
```java
@Entity
@Table(name = "recruit_metadata")
public class RecruitMetadataEntity extends BaseMetadataEntity {
    private String companyName;
    private Integer expYears;
    private String englishLevel;
    private String primaryKeyword;
}

@Entity
@Table(name = "recruit_embedding")
public class RecruitEmbeddingEntity extends BaseEmbeddingEntity {
    public static final int VECTOR_DIMENSION = 384;

    public static RecruitEmbeddingEntity fromFloatArray(UUID id, float[] vectorArray) {
        if (vectorArray.length != VECTOR_DIMENSION) {
            throw new IllegalArgumentException("Vector dimension mismatch");
        }

        RecruitEmbeddingEntity entity = new RecruitEmbeddingEntity();
        entity.setId(id);
        entity.setVector(new PGvector(vectorArray));
        return entity;
    }
}
```

#### 2. Repository (Upsert)
```java
public interface RecruitMetadataRepository extends JpaRepository<RecruitMetadataEntity, UUID> {

    @Modifying
    @Query(value = """
        INSERT INTO recruit_metadata (id, company_name, exp_years, english_level, primary_keyword, created_at, updated_at)
        VALUES (:#{#entity.id}, :#{#entity.companyName}, :#{#entity.expYears}, :#{#entity.englishLevel}, :#{#entity.primaryKeyword}, :#{#entity.createdAt}, :#{#entity.updatedAt})
        ON CONFLICT (id) DO UPDATE SET
            company_name = EXCLUDED.company_name,
            exp_years = EXCLUDED.exp_years,
            english_level = EXCLUDED.english_level,
            primary_keyword = EXCLUDED.primary_keyword,
            updated_at = EXCLUDED.updated_at
        """, nativeQuery = true)
    void upsert(@Param("entity") RecruitMetadataEntity entity);

    default void upsertAll(List<RecruitMetadataEntity> entities) {
        for (RecruitMetadataEntity entity : entities) {
            upsert(entity);
        }
    }
}
```

#### 3. Job ë“±ë¡
```java
@Configuration
public class BatchJobConfig {

    @Bean
    public Job recruitEmbeddingProcessingJob(DomainJobFactory factory) {
        return factory.createJob("recruit");
    }
}
```

#### 4. Scheduler ì„¤ì •
```yaml
batch:
  scheduler:
    enabled: true
    jobs:
      recruit:
        cron: "0 0 2 * * ?"
        enabled: true
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. Chunk Size ì¡°ì •
```yaml
batch:
  embedding:
    chunk-size: 300  # 100-500 ì‚¬ì´ ì¡°ì •
```

### 2. HikariCP ìµœì í™”
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
```

### 3. JPA Batch Size
```yaml
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          batch_size: 300  # Chunk Sizeì™€ ë™ì¼
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- **ë„ë©”ì¸ í™•ì¥ ê°€ì´ë“œ**: `/docs/ë„ë©”ì¸_í™•ì¥_ê°€ì´ë“œ.md`
- **ë™ì‹œì„± ì œì–´ ê°€ì´ë“œ**: `/docs/ë™ì‹œì„±_ì œì–´_ê°€ì´ë“œ.md`
- **Backend ê³µí†µ ë¬¸ì„œ**:
  - `/Backend/docs/DB_ìŠ¤í‚¤ë§ˆ_ê°€ì´ë“œ.md`
  - `/Backend/docs/table_specification.md`
  - `/Backend/docs/Flyway_ë§ˆì´ê·¸ë ˆì´ì…˜_ê°€ì´ë“œ.md`

---

**ìµœì¢… ìˆ˜ì •ì¼**: 2025-12-17
