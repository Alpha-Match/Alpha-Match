# Batch Server - 설계 원칙 정립 및 DLQ 전략 수립

**날짜:** 2025-12-17
**작업 범위:** Spring Batch 책임 분리 원칙 검증 및 DLQ 전략 재설계

---

## 배경

### 문제 상황
1. **설계 원칙 검증 필요**
   - Spring Batch 6.0으로 마이그레이션 완료 (2025-12-16~17)
   - 2개의 설계 문서 제공 (김태현 작성)
   - 현재 구현이 설계 원칙에 부합하는지 검증 필요

2. **DLQ 전략 불완전**
   - Processor에서 발생한 예외가 DLQ에 저장되지 않음
   - Writer만 DLQ 처리 → 비즈니스 로직 실패 데이터 손실 위험
   - Processor와 Writer의 DLQ 책임 구분 필요

### 제공된 설계 문서

#### 문서 1: "Spring Batch 관점에서 본 전체 플로우와 책임 분리 설계.md" (264 lines)
**핵심 원칙:**
1. **Reader는 데이터를 이해하지 않는다**
   - Reader는 Proto 상태로 보관 (역직렬화 금지)
   - Chunk 기반 pull 방식
   - Spring Batch가 read() 호출 시점 제어

2. **Processor는 역직렬화와 비즈니스 검증**
   - Proto → Entity 변환
   - 유효성 검증 (dimension, required fields)
   - 실패 시 DLQ 저장 (제안)

3. **Writer는 IO Sink**
   - 검증된 Entity만 Upsert
   - 인프라 실패 (DB, FK 제약조건) 처리

4. **Transport Chunk ≠ Process Chunk**
   - Transport Chunk: gRPC Stream에서 네트워크 효율을 위한 묶음 (예: 1000개)
   - Process Chunk: Spring Batch Transaction 단위 (예: 100개)
   - Reader가 Transport Chunk를 받아서 Process Chunk로 분해

#### 문서 2: "Reactive Java와 Batch 간 책임 분리를 통한 Backpressure 설계.md" (209 lines)
**핵심 원칙:**
1. **Backpressure는 Spring Batch의 책임이 아니다**
   - Spring Batch는 순차 처리 (read → process → write)
   - Backpressure는 Reactive 레이어에서 제어해야 함

2. **Reactive Flux로 Backpressure 제어**
   - gRPC Stream → Flux → limitRate(N) → Reader의 Queue
   - Spring Batch가 read() 호출 → Queue poll() → Flux가 자동으로 다음 아이템 요청

3. **Virtual Thread는 Flow Control이 아니다**
   - Virtual Thread: 처리 효율 (Blocking → Non-blocking 전환)
   - Backpressure: 데이터 흐름 제어 (생산 속도 vs 소비 속도)
   - Virtual Thread만으로는 Backpressure 해결 불가

---

## 현재 구현 검증

### 1. Reader 책임 분리 검증 ✅

**현재 구현** (DomainItemReader.java):
```java
public abstract class DomainItemReader<T> implements ItemReader<T> {
    protected final BlockingQueue<T> rowQueue = new LinkedBlockingQueue<>(1000);
    protected final AtomicBoolean streamCompleted = new AtomicBoolean(false);

    @Override
    public T read() throws Exception {
        T row = rowQueue.poll(100, TimeUnit.MILLISECONDS);

        if (row != null) {
            return row;  // ✅ Proto 객체 그대로 반환 (역직렬화 안 함)
        }

        if (streamCompleted.get() && rowQueue.isEmpty()) {
            return null;  // Stream 종료
        }

        return read();  // 재시도
    }

    public abstract void startStreaming(UUID lastCheckpoint);
}
```

**검증 결과:**
- ✅ Reader는 Proto 객체를 `BlockingQueue<T>`에 저장
- ✅ 역직렬화 없이 그대로 반환
- ✅ Spring Batch가 read() 호출 시점 제어
- ✅ **설계 원칙 준수**

### 2. Processor 책임 분리 검증 ✅ (부분 이슈 있음)

**현재 구현** (DomainItemProcessor.java):
```java
public abstract class DomainItemProcessor<I, M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemProcessor<I, DomainItem<M, E>> {

    @Override
    public DomainItem<M, E> process(I protoRow) throws Exception {
        try {
            // ✅ Proto → Entity 변환 (역직렬화)
            UUID id = extractId(protoRow);
            M metadata = createMetadata(protoRow, id);

            // ✅ 비즈니스 검증 (dimension, required fields)
            float[] vectorArray = extractVectorArray(protoRow);
            E embedding = createEmbedding(id, vectorArray);

            return new DomainItem<>(metadata, embedding);

        } catch (Exception e) {
            log.error("[PROCESSOR] Domain: {} | Failed to process row | Error: {}",
                    getDomainName(), e.getMessage());
            throw e;  // ❌ 문제: DLQ 저장 없음
        }
    }

    protected abstract M createMetadata(I protoRow, UUID id);
    protected abstract E createEmbedding(UUID id, float[] vectorArray);
}
```

**검증 결과:**
- ✅ Proto → Entity 변환 수행
- ✅ 비즈니스 검증 로직 포함
- ❌ **예외 발생 시 DLQ 저장 없음** (설계 원칙 불일치)
- ❌ Spring Batch의 skip 메커니즘에 의존 (데이터 손실 위험)

### 3. Writer 책임 분리 검증 ✅

**현재 구현** (DomainItemWriter.java):
```java
public class DomainItemWriter<M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemWriter<DomainItem<M, E>> {

    @Override
    public void write(Chunk<? extends DomainItem<M, E>> chunk) throws Exception {
        List<M> metadataList = new ArrayList<>();
        List<E> embeddingList = new ArrayList<>();

        // ✅ IO Sink: 검증된 Entity만 Upsert
        for (DomainItem<M, E> item : chunk.getItems()) {
            try {
                M metadata = item.getMetadata();
                E embedding = item.getEmbedding();

                // 유효성 재검증
                if (metadata.getId() == null) {
                    throw new IllegalStateException("Metadata ID is null");
                }

                metadataList.add(metadata);
                embeddingList.add(embedding);

            } catch (Exception e) {
                // ✅ 개별 아이템 실패 → DLQ 저장
                String payloadJson = jsonMapper.writeValueAsString(item);
                dlqService.saveToDlq(domain, failedId, e.getMessage(), payloadJson);
            }
        }

        try {
            // ✅ Batch Upsert (인프라 작업)
            metadataRepository.saveAll(metadataList);
            embeddingRepository.saveAll(embeddingList);

        } catch (Exception e) {
            // ✅ Batch 실패 → 전체 DLQ 저장
            log.error("[WRITER] Batch upsert failed");
            saveBatchToDlq(metadataList, e.getMessage());
            throw new RuntimeException("Batch upsert failed", e);
        }
    }
}
```

**검증 결과:**
- ✅ IO Sink 역할만 수행
- ✅ 인프라 실패 (DB, FK 제약조건) 처리
- ✅ 개별 아이템 실패 + Batch 실패 모두 DLQ 저장
- ✅ **설계 원칙 준수**

---

## Backpressure 전략 결정

### Option A: Reactive Flux 기반 Backpressure (설계 문서 제안)

**아키텍처:**
```
gRPC Stream
  ↓
Flux<ProtoRow>
  ↓ limitRate(100)  ← Backpressure 제어
Reader.rowQueue (capacity: 100)
  ↓
Spring Batch read()
```

**구현 예시:**
```java
public void startStreaming(UUID lastCheckpoint) {
    Flux.create(sink -> {
        StreamObserver<ProtoRow> observer = new StreamObserver<>() {
            public void onNext(ProtoRow row) {
                sink.next(row);  // Flux로 방출
            }
        };
        grpcClient.streamEmbedding(lastCheckpoint, observer);
    })
    .limitRate(100)  // ✅ Backpressure: 100개씩만 요청
    .doOnNext(row -> {
        try {
            rowQueue.put(row);  // Queue에 저장
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    })
    .subscribe();
}
```

**장점:**
- ✅ Reactive Backpressure 표준 패턴
- ✅ gRPC Stream 속도를 Spring Batch 처리 속도에 맞춤
- ✅ Queue 오버플로우 방지

**단점:**
- ❌ 복잡도 증가 (Reactive + Blocking 혼합)
- ❌ Reactor 의존성 추가
- ❌ 현재 BlockingQueue 구현 대체 필요

### Option B: BlockingQueue 기반 Backpressure (현재 구현)

**아키텍처:**
```
gRPC Stream
  ↓
rowQueue.put()  ← Blocking (Queue full 시 대기)
  ↓
Spring Batch read()
  ↓ rowQueue.poll()
```

**현재 구현:**
```java
protected final BlockingQueue<T> rowQueue = new LinkedBlockingQueue<>(1000);

// gRPC StreamObserver
public void onNext(RecruitRow row) {
    try {
        rowQueue.put(row);  // ✅ Queue full 시 Blocking (Backpressure)
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}
```

**장점:**
- ✅ 단순하고 명확한 구현
- ✅ JDK 표준 API (BlockingQueue)
- ✅ 실제로 Backpressure 효과 (put()이 blocking)
- ✅ 현재 동작 검증 완료 (141,897 rows 처리 성공)

**단점:**
- ❌ Reactive Backpressure 표준이 아님
- ❌ Queue 크기 고정 (1000) → 튜닝 필요 시 코드 변경

### 결정: Option B (BlockingQueue) 유지 ✅

**이유:**
1. **Pragmatic Approach**: 현재 구현으로 충분히 Backpressure 달성
   - BlockingQueue.put()은 Queue full 시 자동 대기
   - gRPC Stream이 Spring Batch 처리 속도에 맞춰짐

2. **검증 완료**: 141,897 rows 처리 성공 (2025-12-11)
   - Queue 오버플로우 없음
   - 메모리 안정적

3. **단순성**: Reactive 의존성 없이 JDK 표준만으로 해결
   - 코드 복잡도 최소화
   - 유지보수 용이

4. **성능 요구사항 충족**: 현재 처리량으로 충분
   - 도메인 추가 시에도 동일 패턴 적용 가능

**모니터링 전략:**
```java
// 향후 Queue 크기 모니터링 추가 (선택)
@Scheduled(fixedDelay = 5000)
public void monitorQueueSize() {
    int size = rowQueue.size();
    if (size > 800) {  // 80% 임계값
        log.warn("[READER] Queue size: {} (80% full)", size);
    }
}
```

**미래 고려사항:**
- 성능 문제 발생 시 Option A (Reactive Flux)로 전환 가능
- 현재는 BlockingQueue로 충분

---

## DLQ 전략 재설계

### 현재 DLQ 구현 문제점

#### 문제 1: Processor 예외가 DLQ에 저장되지 않음

**현재 코드** (DomainItemProcessor.java, line 68-71):
```java
catch (Exception e) {
    log.error("[PROCESSOR] Domain: {} | Failed to process row | Error: {}",
            getDomainName(), e.getMessage());
    throw e;  // ❌ DLQ 없음, Spring Batch skip에 의존
}
```

**문제점:**
1. **데이터 손실 위험**: Processor에서 예외 발생 시 해당 아이템은 Writer에 도달하지 않음
2. **비즈니스 로직 실패 추적 불가**:
   - 유효성 검증 실패 (dimension 불일치, required field 누락)
   - Proto 역직렬화 실패
   - 비즈니스 규칙 위반
3. **Spring Batch Skip에 의존**: SkipPolicy로 넘어가면 로그만 남고 재처리 불가

#### 문제 2: DLQ 책임이 Writer에만 집중

**현재 DLQ 처리:**
- ✅ Writer: 개별 아이템 실패 → DLQ 저장
- ✅ Writer: Batch Upsert 실패 → DLQ 저장
- ❌ Processor: 예외 throw만 함 → DLQ 없음

**결과:**
- 인프라 실패 (DB, FK 제약조건)만 DLQ에 저장
- 비즈니스 로직 실패는 DLQ에 저장되지 않음

### Proposal A: Processor-First DLQ 전략 (권장) ✅

#### 책임 분리 원칙

| Failure Type | Example | Responsible | DLQ Stage | Payload Type | Retry 가능성 |
|--------------|---------|-------------|-----------|--------------|-------------|
| **Business Logic** | Validation failure (dimension 불일치) | Processor | Processor | Proto (원본) | 낮음 (데이터 수정 필요) |
| **Business Logic** | Required field 누락 | Processor | Processor | Proto (원본) | 낮음 (데이터 수정 필요) |
| **Data Transformation** | Proto 역직렬화 실패 | Processor | Processor | Proto (원본) | 낮음 (스키마 불일치) |
| **Business Logic** | 비즈니스 규칙 위반 | Processor | Processor | Proto (원본) | 낮음 (데이터 수정 필요) |
| **Infrastructure** | DB Connection failure | Writer | Writer | Entity (변환됨) | 높음 (일시적 장애) |
| **Infrastructure** | FK Constraint violation | Writer | Writer | Entity (변환됨) | 중간 (참조 데이터 추가 필요) |
| **Infrastructure** | Unique Constraint violation | Writer | Writer | Entity (변환됨) | 낮음 (중복 데이터) |
| **Infrastructure** | Disk full, Timeout | Writer | Writer | Entity (변환됨) | 높음 (일시적 장애) |

#### 핵심 설계 원칙

1. **Processor는 비즈니스 실패를 책임진다**
   - 유효성 검증 실패 → DLQ 저장 (Proto payload)
   - 데이터 변환 실패 → DLQ 저장 (Proto payload)
   - **실패 시 null 반환** (Writer로 전달하지 않음)

2. **Writer는 인프라 실패를 책임진다**
   - DB 연결 실패 → DLQ 저장 (Entity payload)
   - FK 제약조건 위반 → DLQ 저장 (Entity payload)
   - **null 아이템은 skip** (Processor에서 이미 DLQ 저장)

3. **Payload 타입 구분**
   - Processor DLQ: Proto (원본 데이터, 재처리 시 전체 프로세스 재실행)
   - Writer DLQ: Entity (변환된 데이터, 재처리 시 DB 작업만 재실행)

#### 구현 예시

**1) DlqEntity 확장**

```java
@Entity
@Table(name = "dlq")
public class DlqEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(name = "domain", nullable = false, length = 50)
    private String domain;  // "recruit", "candidate"

    @Column(name = "failure_type", nullable = false, length = 50)
    @Enumerated(EnumType.STRING)
    private DlqFailureType failureType;  // ✅ NEW

    @Column(name = "payload_type", nullable = false, length = 20)
    @Enumerated(EnumType.STRING)
    private DlqPayloadType payloadType;  // ✅ NEW

    @Column(name = "failure_stage", nullable = false, length = 20)
    @Enumerated(EnumType.STRING)
    private DlqFailureStage failureStage;  // ✅ NEW

    @Column(name = "status", nullable = false, length = 20)
    @Enumerated(EnumType.STRING)
    private DlqStatus status;  // ✅ NEW

    @Column(name = "failed_id", length = 255)
    private String failedId;

    @Column(name = "error_message", columnDefinition = "TEXT")
    private String errorMessage;

    @Column(name = "payload", columnDefinition = "TEXT")
    private String payload;

    @Column(name = "retry_count")
    private Integer retryCount = 0;  // ✅ NEW

    @Column(name = "last_retry_at")
    private LocalDateTime lastRetryAt;  // ✅ NEW

    @Column(name = "created_at")
    private LocalDateTime createdAt;

    @Column(name = "updated_at")
    private LocalDateTime updatedAt;
}

public enum DlqFailureType {
    VALIDATION,           // 유효성 검증 실패
    PROCESSING,           // 데이터 변환 실패
    BUSINESS_RULE,        // 비즈니스 규칙 위반
    DB_UPSERT,            // DB Upsert 실패
    DB_CONNECTION,        // DB 연결 실패
    FK_CONSTRAINT,        // FK 제약조건 위반
    UNIQUE_CONSTRAINT     // Unique 제약조건 위반
}

public enum DlqPayloadType {
    PROTO,    // Proto 원본 (Processor 실패)
    ENTITY    // Entity 변환됨 (Writer 실패)
}

public enum DlqFailureStage {
    PROCESSOR,  // Processor에서 실패
    WRITER      // Writer에서 실패
}

public enum DlqStatus {
    PENDING,    // 재처리 대기
    RETRYING,   // 재처리 중
    RESOLVED,   // 재처리 성공
    FAILED      // 재처리 실패 (최종)
}
```

**2) DomainItemProcessor 수정**

```java
public abstract class DomainItemProcessor<I, M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemProcessor<I, DomainItem<M, E>> {

    protected final DlqService dlqService;  // ✅ DlqService 주입
    protected final JsonMapper jsonMapper;

    @Override
    public DomainItem<M, E> process(I protoRow) throws Exception {
        try {
            // Proto → Entity 변환
            UUID id = extractId(protoRow);
            M metadata = createMetadata(protoRow, id);

            // 비즈니스 검증
            float[] vectorArray = extractVectorArray(protoRow);
            validateVector(vectorArray);  // ✅ 유효성 검증

            E embedding = createEmbedding(id, vectorArray);

            return new DomainItem<>(metadata, embedding);

        } catch (ValidationException e) {
            // ✅ 비즈니스 로직 실패 → DLQ 저장 (Proto payload)
            saveProcessorDlq(protoRow, e, DlqFailureType.VALIDATION);
            return null;  // ✅ Writer로 전달하지 않음

        } catch (IllegalArgumentException e) {
            // ✅ 데이터 변환 실패 → DLQ 저장 (Proto payload)
            saveProcessorDlq(protoRow, e, DlqFailureType.PROCESSING);
            return null;

        } catch (Exception e) {
            // ✅ 기타 예외 → DLQ 저장
            saveProcessorDlq(protoRow, e, DlqFailureType.PROCESSING);
            return null;
        }
    }

    protected void validateVector(float[] vectorArray) throws ValidationException {
        int expectedDimension = getExpectedVectorDimension();
        if (vectorArray.length != expectedDimension) {
            throw new ValidationException(
                String.format("Vector dimension mismatch: expected %d, got %d",
                        expectedDimension, vectorArray.length)
            );
        }
    }

    private void saveProcessorDlq(I protoRow, Exception e, DlqFailureType failureType) {
        try {
            UUID id = extractId(protoRow);
            String payloadJson = serializeProto(protoRow);  // ✅ Proto 직렬화

            dlqService.saveToDlq(
                getDomainName(),
                id.toString(),
                e.getMessage(),
                payloadJson,
                failureType,           // ✅ 실패 타입
                DlqPayloadType.PROTO,  // ✅ Payload 타입: Proto
                DlqFailureStage.PROCESSOR  // ✅ 실패 단계: Processor
            );

            log.warn("[PROCESSOR] Saved to DLQ | Domain: {} | ID: {} | Type: {} | Error: {}",
                    getDomainName(), id, failureType, e.getMessage());

        } catch (Exception dlqException) {
            log.error("[PROCESSOR] Failed to save to DLQ", dlqException);
        }
    }

    protected abstract String serializeProto(I protoRow) throws Exception;
    protected abstract int getExpectedVectorDimension();
}
```

**3) DomainItemWriter 수정**

```java
public class DomainItemWriter<M extends BaseMetadataEntity, E extends BaseEmbeddingEntity>
        implements ItemWriter<DomainItem<M, E>> {

    @Override
    public void write(Chunk<? extends DomainItem<M, E>> chunk) throws Exception {
        List<M> metadataList = new ArrayList<>();
        List<E> embeddingList = new ArrayList<>();

        for (DomainItem<M, E> item : chunk.getItems()) {
            // ✅ Processor에서 실패한 아이템은 null → skip
            if (item == null) {
                continue;
            }

            try {
                M metadata = item.getMetadata();
                E embedding = item.getEmbedding();

                // 최종 검증 (Writer 단계)
                if (metadata.getId() == null) {
                    throw new IllegalStateException("Metadata ID is null");
                }

                metadataList.add(metadata);
                embeddingList.add(embedding);

            } catch (Exception e) {
                // ✅ Writer 단계 검증 실패 → DLQ 저장 (Entity payload)
                saveWriterDlq(item, e, DlqFailureType.VALIDATION);
            }
        }

        // ✅ Processor에서 모두 실패한 경우 Batch Upsert skip
        if (metadataList.isEmpty()) {
            log.warn("[WRITER] No valid items to write (all failed in Processor)");
            return;
        }

        try {
            // Batch Upsert
            metadataRepository.saveAll(metadataList);
            embeddingRepository.saveAll(embeddingList);

            log.info("[WRITER] Batch upsert success | Count: {}", metadataList.size());

        } catch (DataAccessException e) {
            // ✅ 인프라 실패 → 전체 DLQ 저장 (Entity payload)
            log.error("[WRITER] Batch upsert failed | Error: {}", e.getMessage());

            DlqFailureType failureType = determineFailureType(e);
            for (int i = 0; i < metadataList.size(); i++) {
                M metadata = metadataList.get(i);
                E embedding = embeddingList.get(i);
                DomainItem<M, E> item = new DomainItem<>(metadata, embedding);
                saveWriterDlq(item, e, failureType);
            }

            throw new RuntimeException("Batch upsert failed", e);
        }
    }

    private void saveWriterDlq(DomainItem<M, E> item, Exception e, DlqFailureType failureType) {
        try {
            String payloadJson = jsonMapper.writeValueAsString(item);  // ✅ Entity 직렬화

            dlqService.saveToDlq(
                domain,
                item.getMetadata().getId().toString(),
                e.getMessage(),
                payloadJson,
                failureType,           // ✅ 실패 타입
                DlqPayloadType.ENTITY, // ✅ Payload 타입: Entity
                DlqFailureStage.WRITER // ✅ 실패 단계: Writer
            );

            log.warn("[WRITER] Saved to DLQ | Domain: {} | ID: {} | Type: {} | Error: {}",
                    domain, item.getMetadata().getId(), failureType, e.getMessage());

        } catch (Exception dlqException) {
            log.error("[WRITER] Failed to save to DLQ", dlqException);
        }
    }

    private DlqFailureType determineFailureType(DataAccessException e) {
        String message = e.getMessage();
        if (message.contains("foreign key constraint")) {
            return DlqFailureType.FK_CONSTRAINT;
        } else if (message.contains("unique constraint")) {
            return DlqFailureType.UNIQUE_CONSTRAINT;
        } else if (message.contains("connection")) {
            return DlqFailureType.DB_CONNECTION;
        }
        return DlqFailureType.DB_UPSERT;
    }
}
```

**4) DlqService 확장**

```java
@Service
public class DlqService {

    private final DlqRepository dlqRepository;
    private final JsonMapper jsonMapper;

    public void saveToDlq(
            String domain,
            String failedId,
            String errorMessage,
            String payload,
            DlqFailureType failureType,
            DlqPayloadType payloadType,
            DlqFailureStage failureStage
    ) {
        DlqEntity dlq = new DlqEntity();
        dlq.setDomain(domain);
        dlq.setFailedId(failedId);
        dlq.setErrorMessage(errorMessage);
        dlq.setPayload(payload);
        dlq.setFailureType(failureType);          // ✅ NEW
        dlq.setPayloadType(payloadType);          // ✅ NEW
        dlq.setFailureStage(failureStage);        // ✅ NEW
        dlq.setStatus(DlqStatus.PENDING);         // ✅ NEW
        dlq.setRetryCount(0);                     // ✅ NEW
        dlq.setCreatedAt(LocalDateTime.now());
        dlq.setUpdatedAt(LocalDateTime.now());

        dlqRepository.save(dlq);
    }
}
```

#### 처리 흐름 예시

**시나리오 1: Processor에서 Validation 실패**
```
gRPC Stream → Reader.read() → Processor.process()
                                   ↓ (Vector dimension 불일치)
                                   ↓ ValidationException
                                   ↓ saveProcessorDlq()
                                   ↓   - failureType: VALIDATION
                                   ↓   - payloadType: PROTO
                                   ↓   - failureStage: PROCESSOR
                                   ↓   - status: PENDING
                                   ↓ return null
                                   ↓
Writer.write() → item == null → skip  ✅ DLQ 저장 완료
```

**시나리오 2: Writer에서 FK Constraint 실패**
```
gRPC Stream → Reader.read() → Processor.process()
                                   ↓ (성공)
                                   ↓ return DomainItem<M,E>
                                   ↓
Writer.write() → metadataRepository.saveAll()
                   ↓ (FK 제약조건 위반)
                   ↓ DataAccessException
                   ↓ saveWriterDlq()
                   ↓   - failureType: FK_CONSTRAINT
                   ↓   - payloadType: ENTITY
                   ↓   - failureStage: WRITER
                   ↓   - status: PENDING
                   ✅ DLQ 저장 완료
```

**시나리오 3: Processor에서 Proto 역직렬화 실패**
```
gRPC Stream → Reader.read() → Processor.process()
                                   ↓ createMetadata(protoRow)
                                   ↓ (Proto 필드 누락)
                                   ↓ IllegalArgumentException
                                   ↓ saveProcessorDlq()
                                   ↓   - failureType: PROCESSING
                                   ↓   - payloadType: PROTO
                                   ↓   - failureStage: PROCESSOR
                                   ↓ return null
                                   ↓
Writer.write() → item == null → skip  ✅ DLQ 저장 완료
```

---

## 기술 결정 사항

### 1. Backpressure 전략: BlockingQueue 유지 ✅

**결정:**
- 현재 BlockingQueue(1000) 방식 유지
- Reactive Flux 방식은 성능 문제 발생 시 고려

**이유:**
- 현재 구현으로 충분히 Backpressure 달성 (검증 완료)
- 단순성 및 유지보수성 우선
- JDK 표준 API만으로 해결

**모니터링:**
- Queue 크기 80% 임계값 알림 추가 (선택)

### 2. DLQ 전략: Processor-First 방식 채택 ✅

**결정:**
- Proposal A (Processor-First DLQ 전략) 구현
- Processor와 Writer의 DLQ 책임 명확히 분리

**이유:**
1. **데이터 손실 방지**: 비즈니스 로직 실패도 DLQ에 저장
2. **책임 분리 명확화**:
   - Processor: 비즈니스 실패 (Validation, Processing)
   - Writer: 인프라 실패 (DB, FK Constraint)
3. **재처리 전략 차별화**:
   - Proto payload: 전체 프로세스 재실행
   - Entity payload: DB 작업만 재실행

**구현 범위:**
1. DlqEntity 확장 (failureType, payloadType, failureStage, status, retryCount)
2. DomainItemProcessor에 DLQ 로직 추가
3. DomainItemWriter의 null 아이템 skip 로직 추가
4. DlqService 확장

### 3. 설계 원칙 준수 확인 ✅

**검증 결과:**
- ✅ Reader: Proto 상태 보관 (설계 원칙 준수)
- ⚠️ Processor: 역직렬화 수행 (설계 원칙 준수, DLQ 추가 필요)
- ✅ Writer: IO Sink (설계 원칙 준수)
- ✅ Transport vs Process Chunk: 현재 미구현이나 필요 시 적용 가능

**향후 개선 가능 영역:**
- Transport Chunk 분해 로직 (gRPC 1000개 → Spring Batch 100개씩 처리)
- 현재는 1:1 매핑이나 성능 최적화 시 고려

---

## 고정 문서 반영 사항

### Spring_Batch_개발_가이드.md (업데이트 예정)
- Section 추가: "설계 원칙 - 책임 분리"
  - Reader, Processor, Writer의 책임 명시
  - Transport vs Process Chunk 개념
- Section 추가: "Backpressure 전략"
  - BlockingQueue 방식 설명
  - 모니터링 전략
- Section 추가: "DLQ 전략"
  - Processor-First DLQ 전략
  - 책임 분리 테이블
  - 처리 흐름 예시

### 도메인_확장_가이드.md (업데이트 예정)
- Section 5.2 업데이트: Processor 구현 시 DLQ 로직 추가
- Section 5.3 업데이트: Writer 구현 시 null 아이템 skip 로직 추가

### CLAUDE.md (업데이트 예정)
- "설계 원칙" 섹션 추가
- "최근 업데이트" 섹션에 "2025-12-17 - 설계 원칙 정립 및 DLQ 전략 수립" 추가

---

## 다음 단계

### 1. DLQ Proposal A 구현 (우선순위: 높음)
1. DlqEntity 확장
   - 4개 Enum 추가 (DlqFailureType, DlqPayloadType, DlqFailureStage, DlqStatus)
   - retryCount, lastRetryAt 필드 추가
   - Flyway 마이그레이션 작성

2. DomainItemProcessor 수정
   - DlqService 주입
   - validateVector() 메서드 추가
   - saveProcessorDlq() 메서드 추가
   - catch 블록에서 DLQ 저장 후 null 반환

3. DomainItemWriter 수정
   - null 아이템 skip 로직 추가
   - determineFailureType() 메서드 추가
   - saveWriterDlq()에 새로운 파라미터 추가

4. DlqService 확장
   - saveToDlq() 메서드 시그니처 변경 (3개 파라미터 추가)

5. RecruitItemProcessor 구현
   - serializeProto() 구현 (Proto → JSON)
   - getExpectedVectorDimension() 구현 (return 384)

### 2. 테이블 명세서와 엔티티 불일치 파악 (우선순위: 높음)
- `/Backend/docs/table_specification.md` 읽기
- `/Backend/Batch-Server/src/main/java/com/alpha/backend/domain/` 하위 엔티티 검증
- 불일치 사항 문서화
- 필요 시 Flyway 마이그레이션 작성

### 3. 고정 문서 업데이트 (우선순위: 중간)
- Spring_Batch_개발_가이드.md에 설계 원칙 섹션 추가
- 도메인_확장_가이드.md에 DLQ 구현 가이드 추가
- CLAUDE.md에 설계 원칙 요약 추가

---

**작업 완료일:** 2025-12-17
**다음 작업:** DLQ Proposal A 구현 + 테이블 명세서 검증
