# 서비스 레이어 구현 가이드

**작성일:** 2025-12-12
**구현 상태:** 완료 (ChunkProcessor + EmbeddingStreamingService)

---

## 개요

Batch-Server의 gRPC Client와 서비스 레이어 구현이 완료되었습니다.

### 핵심 플로우

```
Python gRPC Stream (Reactive)
  ↓
EmbeddingGrpcClient (Flux<RowChunk>)
  ↓
EmbeddingStreamingService (청크 단위 분할)
  ↓
Virtual Thread Pool로 전환 (jpaScheduler)
  ↓
ChunkProcessor (Blocking JPA)
  ↓
MetadataRepository + EmbeddingRepository
  ↓
PostgreSQL (recruit_metadata + recruit_embedding)
```

---

## 구현된 컴포넌트

### 1. ChunkProcessor

**위치:** `src/main/java/com/alpha/backend/application/ChunkProcessor.java`

**역할:**
- gRPC로 수신한 RowChunk를 Metadata와 Embedding으로 분리
- Metadata 먼저 저장 (FK 제약 조건)
- Embedding 저장 (pgvector)
- 상세 로깅 (스레드, 청크 사이즈, 마지막 UUID, 마지막 데이터)

**핵심 메서드:**

```java
@Transactional
public UUID processChunk(RowChunk chunk)
```

**로깅 형식:**

```
=== Chunk Processing Started ===
Thread: VirtualThread[#123]/runnable@ForkJoinPool-1-worker-1 | Chunk Size: 300
Metadata upsert completed in 45 ms
Embedding upsert completed in 67 ms
=== Chunk Processing Completed ===
Thread: VirtualThread[#123]/runnable@ForkJoinPool-1-worker-1 | Chunk Size: 300 | Last UUID: 550e8400-e29b-41d4-a716-446655440000
Last Data: { company: "삼성전자", position: "Backend Developer", exp_years: 5, vector_dim: 384 }
Processing Time: metadata=45ms, embedding=67ms, total=112ms
```

**주요 기능:**
- Vector 차원 검증 (384)
- float[] 변환
- PGvector 객체 생성
- Upsert 순서 보장 (metadata → embedding)
- 상세 통계 정보 제공

---

### 2. EmbeddingStreamingService

**위치:** `src/main/java/com/alpha/backend/application/EmbeddingStreamingService.java`

**역할:**
- gRPC Streaming 수신 및 처리 오케스트레이션
- Reactive Stream → Virtual Thread 전환
- Checkpoint 관리
- 에러 핸들링 및 재시도

**핵심 메서드:**

#### 2.1 전체 스트리밍

```java
public Mono<StreamingResult> streamAllData()
```

- 처음부터 모든 데이터 스트리밍
- Checkpoint: null

#### 2.2 Checkpoint 재시작

```java
public Mono<StreamingResult> streamFromCheckpoint()
```

- Checkpoint부터 재시작
- 마지막 처리된 UUID 이후 데이터만 수신

#### 2.3 병렬 스트리밍 (고급)

```java
public Mono<StreamingResult> streamWithParallelism(
    UUID lastProcessedUuid,
    int parallelism,      // 병렬도 (권장: 4-8)
    int subChunkSize      // 서브 청크 크기 (권장: 50-100)
)
```

- 큰 청크를 작은 서브 청크로 분할
- 병렬 처리로 처리량 증가
- DB 커넥션 풀 활용 극대화

**처리 플로우:**

```java
stream
    .publishOn(jpaScheduler)              // Virtual Thread로 전환
    .flatMap(chunk ->
        Mono.fromCallable(() -> {
            UUID uuid = chunkProcessor.processChunk(chunk);
            updateCheckpoint(uuid);
            return uuid;
        })
        .subscribeOn(jpaScheduler)        // Virtual Thread에서 실행
        .timeout(Duration.ofMinutes(5))   // 타임아웃
        .retry(batchProperties.getMaxRetry())  // 재시도
    )
    .then(Mono.fromCallable(() -> new StreamingResult(...)))
```

**로깅 형식:**

```
=== Streaming Processing Started ===
Initial UUID: null | Chunk Size: 300
Processing chunk #1 with 300 rows
Processing chunk #2 with 300 rows
...
=== Streaming Processing Completed ===
Total Chunks: 474 | Total Rows: 141,897 | Last UUID: 550e8400-e29b-41d4-a716-446655440000
Processing Time: 12345 ms (12 seconds)
```

---

### 3. EmbeddingStreamRunner

**위치:** `src/main/java/com/alpha/backend/runner/EmbeddingStreamRunner.java`

**역할:**
- 애플리케이션 시작 시 자동 테스트 실행
- 3가지 테스트 모드 제공

**활성화 조건:**

```yaml
grpc:
  test:
    enabled: true  # application.yml
```

**테스트 모드:**

#### 모드 1: 전체 스트리밍

```java
testFullStreaming()  // 처음부터 모든 데이터
```

#### 모드 2: Checkpoint 재시작

```java
testCheckpointStreaming()  // Checkpoint부터 재시작
```

#### 모드 3: 병렬 스트리밍

```java
testParallelStreaming()  // 병렬 처리 (고급)
```

**결과 출력 형식:**

```
================================================================================
Streaming Result Summary
================================================================================
Total Chunks Processed: 474
Total Rows Processed: 141,897
Last Processed UUID: 550e8400-e29b-41d4-a716-446655440000
Total Processing Time: 12345 ms (12.345 seconds)
Processing Speed: 11498.38 rows/sec
================================================================================
```

---

## Vector 차원 검증

### 확인된 설정 (384 차원)

1. **Proto 파일:**
   - `src/main/proto/embedding_stream.proto` line 16
   - Comment: `// Embedding Vector (384 dimension)`

2. **Entity:**
   - `EmbeddingEntity.java` line 28
   - Column definition: `"vector(384)"`

3. **Config:**
   - `BatchProperties.java` line 27
   - `private int vectorDimension = 384;`

4. **application.yml:**
   - line 73
   - `vector-dimension: 384`

### 차원 검증 로직

ChunkProcessor에서 자동 검증:

```java
private void validateVectorDimension(float[] vector, UUID id) {
    int expectedDim = batchProperties.getVectorDimension();
    if (vector.length != expectedDim) {
        throw new IllegalArgumentException(
            "Vector dimension mismatch for UUID " + id +
            ": expected=" + expectedDim + ", actual=" + vector.length
        );
    }
}
```

차원 불일치 시 예외 발생 및 DLQ 처리 예정.

---

## Reactive + Blocking 혼합 전략

### 스케줄러 전환

```java
@Bean(name = "jpaScheduler")
public Scheduler jpaScheduler(Executor virtualThreadExecutor) {
    return Schedulers.fromExecutor(virtualThreadExecutor);
}
```

### Virtual Thread Executor

```java
@Bean(name = "virtualThreadExecutor")
public Executor virtualThreadExecutor() {
    return Executors.newVirtualThreadPerTaskExecutor();
}
```

### 전환 포인트

```java
stream
    .publishOn(jpaScheduler)        // Reactive → Virtual Thread
    .flatMap(chunk ->
        Mono.fromCallable(() -> {
            // Blocking JPA 작업 (Virtual Thread에서 안전)
            return chunkProcessor.processChunk(chunk);
        })
        .subscribeOn(jpaScheduler)
    )
```

**이점:**
- gRPC 수신: Non-blocking (backpressure 지원)
- DB 저장: Blocking (안정성, pgvector 최적화)
- Virtual Thread: OS 스레드 고갈 방지
- DB 커넥션 풀: boundedElastic으로 제어

---

## 에러 핸들링

### 재시도 정책

```yaml
batch:
  embedding:
    max-retry: 3                  # 최대 재시도 횟수
    retry-backoff-ms: 1000       # 재시도 대기 시간
```

### 타임아웃

```java
.timeout(Duration.ofMinutes(5))  // 청크당 5분 타임아웃
```

### 에러 복구

```java
.retry(batchProperties.getMaxRetry())
.onErrorResume(error -> {
    log.error("Failed after {} retries", maxRetry);
    return Mono.empty();  // 해당 청크 스킵, 다음 청크 계속
})
```

### Checkpoint 업데이트

```java
private void updateCheckpoint(UUID lastProcessedUuid) {
    try {
        checkpointRepository.updateLatestCheckpoint(lastProcessedUuid);
    } catch (Exception e) {
        log.error("Failed to update checkpoint: {}", e.getMessage());
        // Checkpoint 실패는 치명적이지 않으므로 계속 진행
    }
}
```

---

## 사용 방법

### 1. Python Server 실행

```bash
cd Demo-Python
python src/grpc_server.py
```

### 2. Batch Server 실행

```bash
cd Backend/Batch-Server
./gradlew bootRun
```

### 3. 자동 테스트 실행

`application.yml`에서 `grpc.test.enabled: true`로 설정하면 자동 실행:

1. Python Server 연결
2. gRPC Streaming 수신
3. Chunk 단위 DB 저장
4. 상세 로깅 출력
5. 결과 요약 출력

### 4. 수동 실행 (Service 직접 호출)

```java
@Autowired
private EmbeddingStreamingService embeddingStreamingService;

// 전체 스트리밍
StreamingResult result = embeddingStreamingService.streamAllData().block();

// Checkpoint 재시작
StreamingResult result = embeddingStreamingService.streamFromCheckpoint().block();

// 병렬 스트리밍
StreamingResult result = embeddingStreamingService.streamWithParallelism(
    null,  // 처음부터
    4,     // 병렬도
    50     // 서브 청크 크기
).block();
```

---

## 성능 최적화 포인트

### 1. Chunk Size 조정

```yaml
batch:
  embedding:
    chunk-size: 300  # 기본값, 100-500 사이 조정 가능
```

**고려사항:**
- 너무 크면: 메모리 부담, 트랜잭션 시간 증가
- 너무 작으면: 네트워크 오버헤드, DB 왕복 증가
- 권장: 300 rows (약 2MB)

### 2. 병렬도 조정

```java
streamWithParallelism(null, 4, 50)
```

**고려사항:**
- 병렬도 = DB 커넥션 풀 크기의 50% 이하
- 서브 청크 크기 = 50-100 rows
- CPU 코어 수 고려

### 3. DB 커넥션 풀

```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20    # 병렬도 * 2 이상
      minimum-idle: 5
```

### 4. JPA Batch Size

```yaml
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          batch_size: 300    # Chunk Size와 동일
```

---

## 로깅 레벨 설정

```yaml
logging:
  level:
    com.alpha.backend.application: DEBUG    # 서비스 레이어 상세 로깅
    com.alpha.backend.grpc: INFO            # gRPC 기본 로깅
    org.hibernate.SQL: DEBUG                # SQL 쿼리 출력
    org.hibernate.type: TRACE               # SQL 파라미터 출력
```

---

## 다음 단계

### 1. DLQ 처리 로직 구현

- 실패한 Row를 DLQ 테이블에 저장
- DLQ 재처리 배치 작업

### 2. 캐시 무효화 통합

- DB 저장 후 API Server에 캐시 무효화 요청
- CacheInvalidateGrpcClient 연동

### 3. Spring Batch Job/Step 구성

- Job: `embeddingProcessingJob`
- Step 1: `receiveEmbeddingStep`
- Step 2: `storeEmbeddingStep`
- Listener: 진행 상황 모니터링

### 4. Scheduler 구현

- Quartz 기반 배치 스케줄러
- Cron 설정: 매일 새벽 2시 실행

---

## 트러블슈팅

### 1. Python Server 연결 실패

**증상:**

```
io.grpc.StatusRuntimeException: UNAVAILABLE
```

**해결:**

```bash
# Python Server 실행 확인
cd Demo-Python
python src/grpc_server.py

# 포트 확인
netstat -an | findstr 50051
```

### 2. Vector 차원 불일치

**증상:**

```
IllegalArgumentException: Vector dimension mismatch
```

**해결:**

1. `application.yml` 확인: `vector-dimension: 384`
2. Proto 파일 확인: `repeated float vector`
3. Python 데이터 확인: pkl 파일의 vector 차원

### 3. DB 커넥션 풀 고갈

**증상:**

```
HikariPool: Connection is not available
```

**해결:**

```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 30  # 증가
```

또는 병렬도 감소:

```java
streamWithParallelism(null, 2, 50)  // 병렬도 4 → 2
```

### 4. Virtual Thread 미사용

**증상:**

로그에 `VirtualThread` 대신 `pool-` 출력

**해결:**

ExecutorConfig 확인:

```java
@Bean(name = "virtualThreadExecutor")
public Executor virtualThreadExecutor() {
    return Executors.newVirtualThreadPerTaskExecutor();  // Java 21 필수
}
```

---

## 참고 문서

- [Batch 설계서](./Batch설계서.md)
- [gRPC 통신 가이드](./gRPC_통신_가이드.md)
- [Reactive + Blocking 혼합전략](./Reactive_Blocking_혼합전략.md)
- [동시성 제어](./동시성_제어.md)
- [DB 스키마](./DB_스키마.md)

---

**최종 수정일:** 2025-12-12
