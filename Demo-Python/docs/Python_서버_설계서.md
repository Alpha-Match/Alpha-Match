# ğŸ“˜ Python AI Embedding Streaming ì„œë²„ ì„¤ê³„ì„œ

*Headhunter-Recruit Matching System â€” Python gRPC Streaming Server*

> ë³¸ ë¬¸ì„œëŠ” `.pkl` íŒŒì¼ì— ì €ì¥ëœ Recruit Embedding ë° Metadataë¥¼
>
> **gRPC Streaming**ì„ í†µí•´ Batch Serverë¡œ ì „ì†¡í•˜ëŠ” Python AI Backend ì„œë²„ì˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œì…ë‹ˆë‹¤.
>
> Python 3.11+ + gRPC + Pandas + NumPy ì¡°í•©ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

---

# 1. **ëª©ì (Purpose)**

```
pkl íŒŒì¼ â†’ Python AI Server â†’ gRPC Streaming â†’ Batch Server
                  â”‚
                  â””â†’ UUID v7/ULID ìƒì„±
```

ë³¸ Python ì„œë²„ëŠ” `.pkl` íŒŒì¼ì— ì €ì¥ëœ **ëŒ€ìš©ëŸ‰ Embedding ë° Metadata**ë¥¼ ë¡œë”©í•˜ê³ ,
ì´ë¥¼ **gRPC Streaming**ìœ¼ë¡œ Batch Serverì— ì „ì†¡í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

**ì¤‘ìš”:** ì´ í”„ë¡œì íŠ¸ëŠ” ë°ëª¨ ëª©ì ì´ë¯€ë¡œ, ì‹¤ì œ AI ëª¨ë¸ í•™ìŠµ/ì¶”ë¡ ì€ í¬í•¨í•˜ì§€ ì•Šê³ 
**pkl íŒŒì¼ ë¡œë”© â†’ Chunk ë¶„í•  â†’ UUID ìƒì„± â†’ gRPC ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡**ë§Œ êµ¬í˜„í•œë‹¤.

---

# 2. ì£¼ìš” ìš”êµ¬ì‚¬í•­

### âœ” ë°ì´í„° ë¡œë”©

> `.pkl` íŒŒì¼ì—ì„œ Embedding ë°ì´í„°ë¥¼ Pandas DataFrameìœ¼ë¡œ ë¡œë”©
>
> ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ í•„ìš”ì‹œ chunk ë‹¨ìœ„ë¡œ ë¡œë”©
>
> ì•½ 500MB í¬ê¸°ì˜ pkl íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥

### âœ” UUID ìƒì„±

> **UUID v7/ULID**ë¥¼ Python ì„œë²„ì—ì„œ ìƒì„±
>
> ì‹œê°„ìˆœ ì •ë ¬ ë³´ì¥ìœ¼ë¡œ DB ì¸ë±ìŠ¤ ì„±ëŠ¥ ìµœì í™”
>
> Batch Serverì—ì„œì˜ AutoIncrement ê²½í•© ì œê±°

### âœ” gRPC Streaming

> **ì„œë²„ ìŠ¤íŠ¸ë¦¬ë° (Server Streaming)**: Batch Server ìš”ì²­ ì‹œ ë°ì´í„° ì „ì†¡
>
> **í´ë¼ì´ì–¸íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (Client Streaming)**: ì‚¬ìš©ì ìš”ì²­ ì‹œ ë°ì´í„° ì „ì†¡
>
> Chunk ë‹¨ìœ„ ì „ì†¡ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
>
> Backpressure ì§€ì›ìœ¼ë¡œ ì•ˆì •ì ì¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì „ì†¡

### âœ” Checkpoint ì§€ì›

> `last_processed_uuid`ë¥¼ ë°›ì•„ ì¤‘ë³µ ì „ì†¡ ë°©ì§€
>
> ì¬ì‹œì‘ ê°€ëŠ¥ì„± ê³ ë ¤í•œ idempotent ì „ëµ

---

# 3. ì „ì²´ ì²˜ë¦¬ íë¦„ êµ¬ì¡°

## 3.1 ì•„í‚¤í…ì²˜ íë¦„ë„

### ì„œë²„ ìŠ¤íŠ¸ë¦¬ë° (Quartz ê¸°ë°˜ ìë™ ë°°ì¹˜)

```mermaid
flowchart LR
    PKL["pkl íŒŒì¼<br>processed_recruitment_data.pkl"]
    LOAD["Data Loader<br>Pandas DataFrame"]
    UUID["UUID Generator<br>UUID v7/ULID"]
    CHUNK["Chunker<br>Split into chunks"]
    GRPC["gRPC Server<br>GetEmbeddings"]
    BS["Batch Server<br>StreamingService"]

    PKL --> LOAD --> UUID --> CHUNK --> GRPC --> BS
```

### í´ë¼ì´ì–¸íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (ì‚¬ìš©ì ìš”ì²­ ê¸°ë°˜)

```mermaid
flowchart LR
    USER["User Request"]
    CLIENT["gRPC Client<br>UploadEmbeddings"]
    CHUNK["Chunker<br>Split into chunks"]
    GRPC["gRPC Server<br>(Batch Server)"]
    RESULT["Upload Result"]

    USER --> CLIENT --> CHUNK --> GRPC --> RESULT
```

---

# 4. ë°ì´í„° êµ¬ì¡°

## 4.1 pkl íŒŒì¼ êµ¬ì¡°

### ì˜ˆìƒ ë°ì´í„° êµ¬ì¡°
```python
# processed_recruitment_data.pkl ë‚´ìš©
[
    {
        'id': 'uuid-string',  # ê¸°ì¡´ ID (ìˆì„ ê²½ìš°)
        'company_name': 'íšŒì‚¬ëª…',
        'exp_years': 5,
        'english_level': 'Advanced',
        'primary_keyword': 'Backend',
        'job_post_vectors': [0.1, 0.2, ..., 0.5]  # 384 dimensions
    },
    ...
]
```

## 4.2 UUID ìƒì„± ì „ëµ

### UUID v7 vs ULID ë¹„êµ

| íŠ¹ì§• | UUID v7 | ULID |
|-----|---------|------|
| **ì‹œê°„ìˆœ ì •ë ¬** | âœ… ë°€ë¦¬ì´ˆ ë‹¨ìœ„ | âœ… ë°€ë¦¬ì´ˆ ë‹¨ìœ„ |
| **í‘œì¤€ ì¤€ìˆ˜** | âœ… RFC 9562 | âš ï¸ ë¹„í‘œì¤€ |
| **ê¸¸ì´** | 36ì (í•˜ì´í”ˆ í¬í•¨) | 26ì (Base32) |
| **Python ì§€ì›** | `uuid6` ë¼ì´ë¸ŒëŸ¬ë¦¬ | `python-ulid` ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| **DB í˜¸í™˜ì„±** | âœ… PostgreSQL UUID íƒ€ì… | âš ï¸ VARCHAR(26) |
| **ì¸ë±ì‹± ì„±ëŠ¥** | â­â­â­â­â­ | â­â­â­â­â­ |
| **ê¶Œì¥ë„** | âœ… **ê¶Œì¥** | ğŸŸ¡ ëŒ€ì•ˆ |

### Python ì½”ë“œ ì˜ˆì œ

```python
# UUID v7 ìƒì„±
from uuid6 import uuid7

def generate_uuid_v7():
    return str(uuid7())

# ULID ìƒì„±
from ulid import ULID

def generate_ulid():
    return str(ULID())
```

**ê¶Œì¥:** PostgreSQLì˜ í‘œì¤€ UUID íƒ€ì…ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ **UUID v7** ì‚¬ìš©

---

# 5. gRPC í†µì‹  íŒ¨í„´

## 5.1 ì„œë²„ ìŠ¤íŠ¸ë¦¬ë° (Server Streaming)

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- Quartz Schedulerê°€ Batch Serverë¥¼ íŠ¸ë¦¬ê±°
- Batch Serverê°€ í´ë¼ì´ì–¸íŠ¸ ì—­í• 
- Python Serverê°€ ì„œë²„ ì—­í• 

### Proto ì •ì˜
```protobuf
service EmbeddingStreamService {
  rpc GetEmbeddings (RequestParams) returns (stream Embedding);
}

message RequestParams {
  string last_processed_uuid = 1;
  int32 chunk_size = 2;
}

message Embedding {
  string id = 1;
  string company_name = 2;
  int32 exp_years = 3;
  string english_level = 4;
  string primary_keyword = 5;
  repeated float vector = 6;
}
```

### Python êµ¬í˜„
```python
class EmbeddingStreamService(
    embedding_stream_pb2_grpc.EmbeddingStreamServiceServicer
):
    def GetEmbeddings(self, request, context):
        """ì„œë²„ ìŠ¤íŠ¸ë¦¬ë°: Batch Server ìš”ì²­ ì‹œ ë°ì´í„° ì „ì†¡"""
        # pkl íŒŒì¼ ë¡œë“œ
        df = load_data_from_pkl()

        # Checkpoint ì²˜ë¦¬
        if request.last_processed_uuid:
            df = df[df['id'] > request.last_processed_uuid]

        chunk_size = request.chunk_size or 300

        # Chunk ë‹¨ìœ„ë¡œ ì „ì†¡
        for chunk_df in chunker(df, chunk_size):
            for _, row in chunk_df.iterrows():
                embedding = embedding_stream_pb2.Embedding(
                    id=str(row['id']),
                    company_name=row['company_name'],
                    exp_years=int(row['exp_years']),
                    english_level=row['english_level'],
                    primary_keyword=row['primary_keyword'],
                    vector=row['job_post_vectors'].tolist()
                )
                yield embedding
```

## 5.2 í´ë¼ì´ì–¸íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (Client Streaming)

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- ì‚¬ìš©ìê°€ ì§ì ‘ Python ì„œë²„ì— ìš”ì²­
- Python Serverê°€ í´ë¼ì´ì–¸íŠ¸ ì—­í• 
- Batch Serverê°€ ì„œë²„ ì—­í• 

### Proto ì •ì˜
```protobuf
service EmbeddingUploadService {
  rpc UploadEmbeddings (stream Embedding) returns (UploadResult);
}

message UploadResult {
  int32 total_count = 1;
  int32 success_count = 2;
  int32 failed_count = 3;
  repeated string failed_ids = 4;
}
```

### Python êµ¬í˜„
```python
def upload_embeddings_to_batch_server():
    """í´ë¼ì´ì–¸íŠ¸ ìŠ¤íŠ¸ë¦¬ë°: ì‚¬ìš©ì ìš”ì²­ ì‹œ ë°ì´í„° ì „ì†¡"""
    channel = grpc.insecure_channel('localhost:50052')
    stub = embedding_upload_pb2_grpc.EmbeddingUploadServiceStub(channel)

    def generate_embeddings():
        df = load_data_from_pkl()
        chunk_size = 300

        for chunk_df in chunker(df, chunk_size):
            for _, row in chunk_df.iterrows():
                embedding = embedding_upload_pb2.Embedding(
                    id=str(row['id']),
                    company_name=row['company_name'],
                    exp_years=int(row['exp_years']),
                    english_level=row['english_level'],
                    primary_keyword=row['primary_keyword'],
                    vector=row['job_post_vectors'].tolist()
                )
                yield embedding

    # ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
    result = stub.UploadEmbeddings(generate_embeddings())
    print(f"Upload completed: {result.success_count}/{result.total_count}")
```

---

# 6. Chunk í¬ê¸° ìµœì í™”

## 6.1 Chunk í¬ê¸° ê°€ì´ë“œë¼ì¸

### ê¶Œì¥ Chunk í¬ê¸°

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ í¬ê¸° | ì´ìœ  |
|---------|---------|-----|
| **ë„¤íŠ¸ì›Œí¬ ì–‘í˜¸** | 500 | gRPC ë©”ì‹œì§€ í¬ê¸° ìµœì í™” |
| **ì¼ë°˜ì ì¸ ê²½ìš°** | 300 | ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì˜ ê· í˜• |
| **ë©”ëª¨ë¦¬ ì œí•œ** | 100 | ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€ |
| **ë””ë²„ê¹…** | 10 | ë¡œê·¸ ì¶”ì  ìš©ì´ |

### Vector í¬ê¸°ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

#### ê³„ì‚°ì‹
```
ë©”ëª¨ë¦¬ = chunk_size Ã— vector_dimension Ã— 4 bytes (float32)
```

#### ì˜ˆì‹œ (1536 ì°¨ì› ê¸°ì¤€)

| Chunk í¬ê¸° | Vector ë©”ëª¨ë¦¬ | Metadata ë©”ëª¨ë¦¬ | ì´ ë©”ëª¨ë¦¬ |
|-----------|-------------|----------------|----------|
| 10 | ~60 KB | ~5 KB | ~65 KB |
| 100 | ~600 KB | ~50 KB | ~650 KB |
| 300 | ~1.8 MB | ~150 KB | ~2 MB |
| 500 | ~3 MB | ~250 KB | ~3.5 MB |
| 1000 | ~6 MB | ~500 KB | ~7 MB |

## 6.2 ë™ì  Chunk í¬ê¸° ì¡°ì •

```python
def calculate_optimal_chunk_size(
    vector_dimension: int = 1536,
    available_memory_mb: float = 100,
    safety_factor: float = 0.5
) -> int:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì  Chunk í¬ê¸° ê³„ì‚°

    Args:
        vector_dimension: Vector ì°¨ì› (ê¸°ë³¸ 1536)
        available_memory_mb: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (MB)
        safety_factor: ì•ˆì „ ì—¬ìœ ìœ¨ (0.5 = 50%)

    Returns:
        ìµœì  Chunk í¬ê¸°
    """
    # Vector ë©”ëª¨ë¦¬ (float32 = 4 bytes)
    vector_bytes = vector_dimension * 4

    # Metadata ëŒ€ëµ 500 bytesë¡œ ê°€ì •
    metadata_bytes = 500

    # ì´ row ë‹¹ ë©”ëª¨ë¦¬
    bytes_per_row = vector_bytes + metadata_bytes

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (ì•ˆì „ ì—¬ìœ ìœ¨ ì ìš©)
    usable_bytes = available_memory_mb * 1024 * 1024 * safety_factor

    # ìµœì  Chunk í¬ê¸°
    optimal_size = int(usable_bytes / bytes_per_row)

    # ìµœì†Œ 10, ìµœëŒ€ 1000ìœ¼ë¡œ ì œí•œ
    return max(10, min(optimal_size, 1000))

# ì‚¬ìš© ì˜ˆì‹œ
chunk_size = calculate_optimal_chunk_size(
    vector_dimension=1536,
    available_memory_mb=100,  # 100MB ì‚¬ìš© ê°€ëŠ¥
    safety_factor=0.5
)
print(f"Optimal chunk size: {chunk_size}")  # ì•½ 300
```

---

# 7. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§

## 7.1 gRPC Status Code í™œìš©

```python
import grpc
from grpc import StatusCode

def GetEmbeddings(self, request, context):
    try:
        # ë°ì´í„° ë¡œë”©
        df = load_data_from_pkl()

        # Streaming
        for chunk in chunker(df, chunk_size):
            yield chunk

    except FileNotFoundError:
        context.set_code(StatusCode.NOT_FOUND)
        context.set_details('pkl file not found')
        return

    except MemoryError:
        context.set_code(StatusCode.RESOURCE_EXHAUSTED)
        context.set_details('Insufficient memory')
        return

    except Exception as e:
        context.set_code(StatusCode.INTERNAL)
        context.set_details(f'Internal error: {str(e)}')
        return
```

## 7.2 ì¬ì‹œë„ ë¡œì§ (Client Streaming)

```python
from grpc import RpcError
import time

def upload_with_retry(max_retries=3, retry_delay=2):
    """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ì—…ë¡œë“œ"""
    for attempt in range(max_retries):
        try:
            result = upload_embeddings_to_batch_server()
            return result

        except RpcError as e:
            if e.code() == StatusCode.UNAVAILABLE:
                if attempt < max_retries - 1:
                    print(f"Retry {attempt + 1}/{max_retries}...")
                    time.sleep(retry_delay)
                    continue
                else:
                    raise
            else:
                raise
```

---

# 8. ì„±ëŠ¥ ìµœì í™” ì „ëµ

## 8.1 Pandas ìµœì í™”

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¡œë”©

```python
import pandas as pd
import numpy as np

def load_data_optimized(pkl_path: str) -> pd.DataFrame:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ pkl íŒŒì¼ ë¡œë”©"""
    # pkl íŒŒì¼ ë¡œë“œ
    df = pd.read_pickle(pkl_path)

    # ë°ì´í„° íƒ€ì… ìµœì í™”
    df['exp_years'] = df['exp_years'].astype(np.int16)
    df['company_name'] = df['company_name'].astype('category')
    df['english_level'] = df['english_level'].astype('category')
    df['primary_keyword'] = df['primary_keyword'].astype('category')

    # VectorëŠ” float32ë¡œ ìœ ì§€ (í•„ìš”ì‹œ float16)
    if isinstance(df['job_post_vectors'].iloc[0], list):
        df['job_post_vectors'] = df['job_post_vectors'].apply(
            lambda x: np.array(x, dtype=np.float32)
        )

    return df
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸

```python
def print_memory_usage(df: pd.DataFrame):
    """DataFrame ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥"""
    memory_usage = df.memory_usage(deep=True)
    total_mb = memory_usage.sum() / 1024 / 1024

    print(f"Total memory usage: {total_mb:.2f} MB")
    print("\nPer column:")
    for col, mem in memory_usage.items():
        print(f"  {col}: {mem / 1024 / 1024:.2f} MB")
```

## 8.2 gRPC ìµœì í™”

### Server Options

```python
def serve():
    # gRPC ì„œë²„ ì˜µì…˜ ìµœì í™”
    options = [
        # ìµœëŒ€ ë©”ì‹œì§€ í¬ê¸° (ê¸°ë³¸ 4MB â†’ 16MB)
        ('grpc.max_send_message_length', 16 * 1024 * 1024),
        ('grpc.max_receive_message_length', 16 * 1024 * 1024),

        # Keep-alive ì„¤ì •
        ('grpc.keepalive_time_ms', 30000),
        ('grpc.keepalive_timeout_ms', 10000),

        # HTTP/2 ì„¤ì •
        ('grpc.http2.max_pings_without_data', 0),
        ('grpc.http2.min_time_between_pings_ms', 10000),
    ]

    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=10),
        options=options
    )

    embedding_stream_pb2_grpc.add_EmbeddingStreamServiceServicer_to_server(
        EmbeddingStreamService(), server
    )

    server.add_insecure_port('[::]:50051')
    server.start()
    server.wait_for_termination()
```

---

# 9. ë°°í¬ ë° ìš´ì˜

## 9.1 í™˜ê²½ ë³€ìˆ˜

```python
# config.py
import os

class Config:
    # ì„œë²„ ì„¤ì •
    GRPC_PORT = int(os.getenv('GRPC_PORT', 50051))
    MAX_WORKERS = int(os.getenv('MAX_WORKERS', 10))

    # ë°ì´í„° ì„¤ì •
    PKL_PATH = os.getenv('PKL_PATH', 'data/processed_recruitment_data.pkl')
    CHUNK_SIZE = int(os.getenv('CHUNK_SIZE', 300))

    # ì„±ëŠ¥ ì„¤ì •
    MAX_MESSAGE_SIZE = int(os.getenv('MAX_MESSAGE_SIZE', 16 * 1024 * 1024))

    # Batch Server ì„¤ì • (Client Streaming)
    BATCH_SERVER_HOST = os.getenv('BATCH_SERVER_HOST', 'localhost')
    BATCH_SERVER_PORT = int(os.getenv('BATCH_SERVER_PORT', 50052))
```

## 9.2 ë¡œê¹…

```python
import logging

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('grpc_server.log'),
            logging.StreamHandler()
        ]
    )

    return logging.getLogger(__name__)

logger = setup_logging()

# ì‚¬ìš© ì˜ˆì‹œ
def GetEmbeddings(self, request, context):
    logger.info(f"GetEmbeddings called with chunk_size={request.chunk_size}")
    # ...
    logger.info(f"Sent {total_count} embeddings")
```

---

# 10. í…ŒìŠ¤íŠ¸

## 10.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
import unittest
from unittest.mock import patch, MagicMock

class TestDataLoader(unittest.TestCase):

    @patch('pandas.read_pickle')
    def test_load_data_optimized(self, mock_read_pickle):
        # Mock DataFrame
        mock_df = pd.DataFrame({
            'id': ['uuid1', 'uuid2'],
            'company_name': ['Company A', 'Company B'],
            'exp_years': [5, 3],
            'english_level': ['Advanced', 'Intermediate'],
            'primary_keyword': ['Backend', 'Frontend'],
            'job_post_vectors': [np.random.rand(1536), np.random.rand(1536)]
        })
        mock_read_pickle.return_value = mock_df

        # Test
        df = load_data_optimized('test.pkl')

        # Assert
        self.assertEqual(len(df), 2)
        self.assertEqual(df['exp_years'].dtype, np.int16)
```

## 10.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
import grpc
import grpc_testing

class TestEmbeddingStreamService(unittest.TestCase):

    def setUp(self):
        # gRPC í…ŒìŠ¤íŠ¸ ì±„ë„ ìƒì„±
        self.channel = grpc_testing.channel([
            embedding_stream_pb2.DESCRIPTOR.services_by_name['EmbeddingStreamService']
        ])

        self.service = EmbeddingStreamService()

    def test_get_embeddings_streaming(self):
        # Request ìƒì„±
        request = embedding_stream_pb2.RequestParams(
            chunk_size=10
        )

        # Streaming í˜¸ì¶œ
        responses = list(self.service.GetEmbeddings(request, None))

        # Assert
        self.assertGreater(len(responses), 0)
        self.assertEqual(len(responses[0].vector), 1536)
```

---

# 11. ì£¼ì˜ì‚¬í•­ ë° Best Practices

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **pkl íŒŒì¼ ì§ì ‘ ì¡°íšŒ ê¸ˆì§€**
   - ìš©ëŸ‰ì´ ë§¤ìš° í¬ë¯€ë¡œ ë©”ëª¨ë¦¬ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
   - ë°˜ë“œì‹œ gRPC ìŠ¤íŠ¸ë¦¬ë°ì„ í†µí•´ì„œë§Œ ì ‘ê·¼

2. **Chunk í¬ê¸° ì¡°ì •**
   - ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë”°ë¼ 100~500 ì‚¬ì´ë¡œ ì¡°ì •
   - ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±, ë„ˆë¬´ ì‘ìœ¼ë©´ ì˜¤ë²„í—¤ë“œ ì¦ê°€

3. **UUID ìˆœì„œ ë³´ì¥**
   - `last_processed_uuid` ì²˜ë¦¬ ì‹œ UUID ìˆœì„œëŒ€ë¡œ ì •ë ¬ í•„ìš”
   - UUID v7/ULIDëŠ” ìë™ìœ¼ë¡œ ì‹œê°„ìˆœ ì •ë ¬ ë³´ì¥

4. **Thread Pool í¬ê¸°**
   - `max_workers` ì„¤ì • ì‹œ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê³ ë ¤
   - ê¶Œì¥: CPU ì½”ì–´ ìˆ˜ Ã— 2

## âœ… Best Practices

1. **UUID v7 ì‚¬ìš©**
   - PostgreSQL UUID íƒ€ì…ê³¼ í˜¸í™˜
   - ì‹œê°„ìˆœ ì •ë ¬ë¡œ ì¸ë±ìŠ¤ ì„±ëŠ¥ ìµœì í™”

2. **ë©”ëª¨ë¦¬ ìµœì í™”**
   - Pandas ë°ì´í„° íƒ€ì… ìµœì í™” (`category`, `int16` ë“±)
   - ë¶ˆí•„ìš”í•œ ë°ì´í„° ì¡°ê¸° ì œê±°

3. **ë¡œê¹… ì „ëµ**
   - ê° Chunk ì „ì†¡ ì‹œ ë¡œê·¸ ê¸°ë¡
   - ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸í•œ ì»¨í…ìŠ¤íŠ¸ í¬í•¨

4. **í™˜ê²½ ë³€ìˆ˜ í™œìš©**
   - í•˜ë“œì½”ë”© ëŒ€ì‹  í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
   - ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬

---

# 12. êµ¬í˜„ ìƒíƒœ (2025-12-11)

## 12.1 êµ¬í˜„ ì™„ë£Œ

### Phase 1: ê¸°ë³¸ êµ¬í˜„ âœ… ì™„ë£Œ
- âœ… Proto íŒŒì¼ ì»´íŒŒì¼ (`embedding_stream.proto`)
- âœ… Data Loader êµ¬í˜„ (`data_loader.py` - 270 lines)
  - `load_data_optimized()`: ë©”ëª¨ë¦¬ ìµœì í™” ë¡œë”©
  - `filter_from_checkpoint()`: Checkpoint í•„í„°ë§
  - 141,897 rows ì„±ê³µì  ë¡œë“œ
  - 5.3% ë©”ëª¨ë¦¬ ì ˆê°
- âœ… UUID Generator êµ¬í˜„ (`uuid_generator.py` - 100 lines)
  - UUID v7 ìƒì„±
  - PostgreSQL í˜¸í™˜
- âœ… ì„œë²„ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ (`grpc_server.py` - 220 lines)
  - StreamEmbedding RPC
  - Port 50051 ë¦¬ìŠ¤ë‹
  - **474 chunks ìŠ¤íŠ¸ë¦¬ë° ì„±ê³µ**
  - **Java Batch Server í†µì‹  ì„±ê³µ**

### Phase 2: ìµœì í™” âœ… ì™„ë£Œ
- âœ… Chunk í¬ê¸° ë™ì  ì¡°ì • (`chunker.py` - 300 lines)
  - `calculate_optimal_chunk_size()`: ë©”ëª¨ë¦¬ ê¸°ë°˜ ê³„ì‚°
  - ì ì‘í˜• chunk í¬ê¸°
- âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
  - ë¡œë”© ì „í›„ ë©”ëª¨ë¦¬ ì¶”ì 
  - ì»¬ëŸ¼ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
- âœ… í™˜ê²½ ì„¤ì • (`config.py` - 120 lines)
  - Server/Data ì„¤ì • ë¶„ë¦¬
  - í™˜ê²½ ë³€ìˆ˜ ì§€ì›

### Phase 3: í…ŒìŠ¤íŠ¸ ë° ìš´ì˜ âœ… ê¸°ë³¸ ì™„ë£Œ
- âœ… í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ êµ¬í˜„ (`grpc_client.py` - 150 lines)
  - StreamEmbedding í˜¸ì¶œ í…ŒìŠ¤íŠ¸
  - ì—°ê²° ê²€ì¦
- âœ… ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
  - `start_server.bat`
  - `test_client.bat`
- âœ… **Batch Server í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ**

## 12.2 ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
```
íŒŒì¼ í¬ê¸°: ~500MB
ì´ ë ˆì½”ë“œ: 141,897 rows
ë©”ëª¨ë¦¬ ìµœì í™”: 5.3% ì ˆê°
ì´ chunks: 474
Chunk í¬ê¸°: 300 rows/chunk
ìŠ¤íŠ¸ë¦¬ë° ì„±ê³µë¥ : 100%
Batch Server ìˆ˜ì‹ : ì„±ê³µ
```

### ì‹¤í–‰ ë¡œê·¸
```
[2025-12-11 15:30:00] INFO [grpc_server] - gRPC Server starting on port 50051
[2025-12-11 15:30:01] INFO [data_loader] - Loaded 141,897 rows
[2025-12-11 15:30:01] INFO [data_loader] - Memory: 546.32 MB â†’ 517.35 MB (5.3% reduction)
[2025-12-11 15:30:05] INFO [grpc_server] - Streaming 474 chunks to Batch Server
[2025-12-11 15:30:15] INFO [grpc_server] - Successfully streamed all chunks
[2025-12-11 15:30:15] INFO [Batch Server] - Received 474 chunks (141,897 rows)
```

## 12.3 ë‚¨ì€ ì‘ì—…

### ìš°ì„ ìˆœìœ„ ë†’ìŒ
- â³ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (`tests/`)
- â³ ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™” (ì¬ì‹œë„ ë¡œì§)
- â³ Health Check ì—”ë“œí¬ì¸íŠ¸

### ìš°ì„ ìˆœìœ„ ì¤‘ê°„
- â³ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ìµœì í™”
- â³ Monitoring ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- â³ ë¡œê¹… ë ˆë²¨ ì„¸ë¶„í™”

### ìš°ì„ ìˆœìœ„ ë‚®ìŒ (ì„ íƒì )
- â³ Client Streaming êµ¬í˜„ (í˜„ì¬ ë¶ˆí•„ìš”)
- â³ Bidirectional Streaming (í˜„ì¬ ë¶ˆí•„ìš”)
- â³ TLS/SSL ì§€ì›

## 12.4 ê´€ë ¨ ë¬¸ì„œ

- [gRPC_ì„œë²„_êµ¬í˜„_ê°€ì´ë“œ.md](./gRPC_ì„œë²„_êµ¬í˜„_ê°€ì´ë“œ.md)
- [ë°ì´í„°_ë¡œë”©_ì „ëµ.md](./ë°ì´í„°_ë¡œë”©_ì „ëµ.md)
- [ìŠ¤íŠ¸ë¦¬ë°_ì „ëµ.md](./ìŠ¤íŠ¸ë¦¬ë°_ì „ëµ.md)
- [UUID_ìƒì„±_ì „ëµ.md](./UUID_ìƒì„±_ì „ëµ.md)
- [í”„ë¡œì íŠ¸_êµ¬ì¡°.md](./í”„ë¡œì íŠ¸_êµ¬ì¡°.md)

---

**ìµœì¢… ìˆ˜ì •ì¼:** 2025-12-11
**êµ¬í˜„ ìƒíƒœ:** Phase 1, 2 ì™„ë£Œ / Batch Server í†µì‹  ì„±ê³µ
